{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ExtractROI - skip dummy scans\n",
    "'''\n",
    "To be checked whether it has to be used or not. It just skips some scans from the window.\n",
    "'''\n",
    "extract = Node(ExtractROI(t_min=4, t_size=-1),\n",
    "               output_type='NIFTI_GZ',\n",
    "               name=\"extract\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (MotionCorrection==1):\n",
    "    # MCFLIRT - motion correction\n",
    "    mcflirt = Node(MCFLIRT(mean_vol=True,\n",
    "                           save_plots=True,\n",
    "                           output_type='NIFTI_GZ'),\n",
    "                   name=\"mcflirt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Smooth - image smoothing\n",
    "smooth = Node(Smooth(),\n",
    "              fwhm = FWHM,\n",
    "              name=\"smooth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if highpass:\n",
    "#     highpass = Node(interface=fsl.ImageMaths(suffix='_tempfilt'),\n",
    "#                           name='highpass')\n",
    "#     #featpreproc.connect(inputnode, ('highpass', highpass_operand), highpass, 'op_string')\n",
    "#     featpreproc.connect(meanscale, 'out_file', highpass, 'in_file')\n",
    "\n",
    "#     \"\"\"\n",
    "#     Add back the mean removed by the highpass filter operation as of FSL 5.0.7\n",
    "#     \"\"\"\n",
    "#     meanfunc4 = Node(interface=fsl.ImageMaths(op_string='-Tmean',\n",
    "#                                                     suffix='_mean'),\n",
    "#                            name='meanfunc4')\n",
    "\n",
    "#     featpreproc.connect(meanscale, 'out_file', meanfunc4, 'in_file')\n",
    "#     addmean = Node(interface=fsl.BinaryMaths(operation='add'),\n",
    "#                          iterfield=['in_file', 'operand_file'],\n",
    "#                          name='addmean')\n",
    "#     featpreproc.connect(highpass, 'out_file', addmean, 'in_file')\n",
    "#     featpreproc.connect(meanfunc4, 'out_file', addmean, 'operand_file')\n",
    "#     featpreproc.connect(addmean, 'out_file', outputnode, 'highpassed_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "art = Node(ArtifactDetect(norm_threshold=2,\n",
    "                          zintensity_threshold=3,\n",
    "                          mask_type='spm_global',\n",
    "                          parameter_source='FSL',\n",
    "                          use_differences=[True, False],\n",
    "                          plot_type='svg'),\n",
    "           name=\"art\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['func', 'anat']),\n",
    "                  name=\"infosource\")\n",
    "\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory=experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "## Use the following DataSink output substitutions\n",
    "substitutions = [('_subject_id_', ''),\n",
    "                 ('_task_name_', '/task-'),\n",
    "                 ('_fwhm_', 'fwhm-'),\n",
    "                 ('_roi', ''),\n",
    "                 ('_mcf', ''),\n",
    "                 ('_st', ''),\n",
    "                 ('_flirt', ''),\n",
    "                 ('.nii_mean_reg', '_mean'),\n",
    "                 ('.nii.par', '.par'),\n",
    "                 ]\n",
    "\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a preprocessing workflow\n",
    "preproc = Workflow(name='preproc')\n",
    "preproc.base_dir = opj(experiment_dir, working_dir)\n",
    "\n",
    "# Connect all components of the preprocessing workflow\n",
    "preproc.connect([(infosource, extract, [('func', 'in_file')]),\n",
    "                 (extract, mcflirt, [('roi_file', 'in_file')]),\n",
    "                 (mcflirt, slicetimer, [('out_file', 'in_file')]),\n",
    "\n",
    "                 (infosource, coregwf, [('anat', 'bet_anat.in_file'),\n",
    "                                         ('anat', 'coreg_bbr.reference')]),\n",
    "                 (mcflirt, coregwf, [('mean_img', 'coreg_pre.in_file'),\n",
    "                                     ('mean_img', 'coreg_bbr.in_file'),\n",
    "                                     ('mean_img', 'applywarp_mean.in_file')]),\n",
    "                 (slicetimer, coregwf, [('slice_time_corrected_file', 'applywarp.in_file')]),\n",
    "                 \n",
    "                 (coregwf, smooth, [('applywarp.out_file', 'in_files')]),\n",
    "#                 (inputnode, highpass,[(('highpass', highpass_operand), 'op_string')]),\n",
    "                 (mcflirt, datasink, [('par_file', 'preproc.@par')]),\n",
    "                 (smooth, datasink, [('smoothed_files', 'preproc.@smooth')]),\n",
    "                 \n",
    "                 (coregwf, datasink, [('applywarp_mean.out_file', 'preproc.@mean')]),\n",
    "\n",
    "                 (coregwf, art, [('applywarp.out_file', 'realigned_files')]),\n",
    "                 (mcflirt, art, [('par_file', 'realignment_parameters')]),\n",
    "\n",
    "                 (coregwf, datasink, [('coreg_bbr.out_matrix_file', 'preproc.@mat_file'),\n",
    "                                      ('bet_anat.out_file', 'preproc.@brain')]),\n",
    "                 (art, datasink, [('outlier_files', 'preproc.@outlier_files'),\n",
    "                                  ('plot_files', 'preproc.@plot_files')]),\n",
    "                 ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create preproc output graph\n",
    "preproc.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename=opj(preproc.base_dir, 'preproc', 'graph.dot.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the detailed graph\n",
    "preproc.write_graph(graph2use='flat', format='png', simple_form=True)\n",
    "Image(filename=opj(preproc.base_dir, 'preproc', 'graph_detailed.dot.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = fsl.ImageStats(op_string='-k %s -p 50', in_file = \"/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3577037/session_1/rest_1/rest_linearMNI3mm.nii.gz\",\n",
    "                   mask_file = \"/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3577037/session_1/rest_1/rest_linearMNI3mm.nii.gz\")\n",
    "ab.cmdline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Graph.size of <networkx.classes.digraph.DiGraph object at 0x7f7e8e16feb8>>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nipype.interfaces.utility as util\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "\n",
    "from nipype.interfaces import fsl\n",
    "import nipype.workflows.fmri.fsl.preprocess as Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_WorkFlow = Preprocessor.create_reg_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageMaths' object has no attribute 'out_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-bd748b30b269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Reg_WorkFlow.connect(meanfunc, 'out_file', Reg_WorkFlow.inputs.inputspec, 'mean_image')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mReg_WorkFlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeanfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageMaths' object has no attribute 'out_file'"
     ]
    }
   ],
   "source": [
    "meanfunc = fsl.ImageMaths(op_string='-Tmean',\n",
    "                                                    suffix='_mean', \n",
    "            in_file = '/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3577037/session_1/rest_1/rest_linearMNI3mm.nii.gz')\n",
    "    \n",
    "\n",
    "#Reg_WorkFlow.connect(meanfunc, 'out_file', Reg_WorkFlow.inputs.inputspec, 'mean_image')\n",
    "Reg_WorkFlow.inputs.inputspec.mean_image = meanfunc.out_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3999447/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3283638/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/2154093/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/1065809/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/4222184/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3334426/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/4098356/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3003775/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/1915879/session_1/rest_1/rest_linearMNI3mm.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import Preprocess_network as parallelPreproc\n",
    "import timeit\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "start = timeit.default_timer()\n",
    "# JSONFile = sys.argv[1]\n",
    "JSONFile = '/home/deepak/Desktop/FConnectivityAnalysis/FConnectivityAnalysisDesign.json'\n",
    "with open(JSONFile) as JSON:\n",
    "    try :\n",
    "        \n",
    "        data = json.load(JSON)\n",
    "        AnalysisName = data['Analysis Name']\n",
    "    #     print(AnalysisName)\n",
    "        WorkingDir = data['WorkingDir']\n",
    "        AnalysisParams = data['AnalysisParams']\n",
    "        \n",
    "    except :\n",
    "        print('Unexpected error:', sys.exc_info()[0])\n",
    "        raise\n",
    "\n",
    "def get_TR(in_file):\n",
    "    import nibabel\n",
    "    f = nibabel.load(in_file)\n",
    "    return f.get_header()['dim'][0]#['pixdim'][1:4].tolist(), f.get_header()['pixdim'][4]\n",
    "\n",
    "\n",
    "def run_Preprocessing(AnalysisParams,FunctionalFiles,StructuralFiles,Group = 0):\n",
    "\n",
    "    ReferenceFile = AnalysisParams['ReferSummary']['ReferImgPath']\n",
    "    B0unwarping = AnalysisParams['B0 Unwarping']\n",
    "    BETextract = AnalysisParams['BET Brain Extract']\n",
    "    FWHM = AnalysisParams['FWHM']\n",
    "    HighPass = AnalysisParams['High Pass']\n",
    "    MotionCorrection = AnalysisParams['Motion Correction']\n",
    "    Registration = AnalysisParams['Registration']\n",
    "    SliceTimeCorrect = AnalysisParams['Slice Time Correct']\n",
    "    Intensity_Norm = AnalysisParams['Intensity Normalization']\n",
    "    MelodicICA = AnalysisParams['Melodic ICA']\n",
    "    PerfusionSubtract = AnalysisParams['Perfusion Subtraction']\n",
    "    OUTPUT_DIR = AnalysisParams['OutputInfo']['OutDirectory']\n",
    "    TEMP_DIR_FOR_STORAGE = OUTPUT_DIR + '/tmp'\n",
    "    FeatProcessName = 'featpreproc_group%s'%Group\n",
    "    RegistrationName = 'registration_group%s'%Group\n",
    "    RESULTS_FEAT_DATASINK = OUTPUT_DIR + '/tmp/%s/datasink/'%FeatProcessName\n",
    "    TR = get_TR(FunctionalFiles[0])\n",
    "    print('Using Repetition time: %s'%TR)\n",
    "    if HighPass:\n",
    "        preproc = parallelPreproc.create_parallelfeat_preproc(name = FeatProcessName,\n",
    "                                    highpass= HighPass, \n",
    "                                    Intensity_Norm = Intensity_Norm,\n",
    "                                    BETextract = BETextract,\n",
    "                                    MotionCorrection = MotionCorrection, \n",
    "                                    SliceTimeCorrect = SliceTimeCorrect,\n",
    "                                    time_repeat = TR)\n",
    "        preproc.inputs.inputspec.highpass = 1/(0.09*TR)\n",
    "        preproc.inputs.inputspec.func = FunctionalFiles\n",
    "        preproc.inputs.inputspec.fwhm = FWHM\n",
    "        preproc.base_dir = TEMP_DIR_FOR_STORAGE\n",
    "        preproc.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "        preproc.run('MultiProc', plugin_args={'n_procs': 4})\n",
    "    else:\n",
    "        preproc = parallelPreproc.create_parallelfeat_preproc(name = FeatProcessName,\n",
    "                                    highpass= HighPass, \n",
    "                                    Intensity_Norm = Intensity_Norm,\n",
    "                                    BETextract = BETextract,\n",
    "                                    MotionCorrection = MotionCorrection, \n",
    "                                    SliceTimeCorrect = SliceTimeCorrect,\n",
    "                                    time_repeat = TR)\n",
    "        preproc.inputs.inputspec.func = FunctionalFiles\n",
    "        preproc.inputs.inputspec.fwhm = FWHM\n",
    "        preproc.base_dir = TEMP_DIR_FOR_STORAGE\n",
    "        preproc.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "        preproc.run('MultiProc', plugin_args={'n_procs': 4})\n",
    "\n",
    "    datasink_results=[]\n",
    "    datasink_results += [each for each in os.listdir(RESULTS_FEAT_DATASINK) if each.endswith('.json')]\n",
    "    with open(RESULTS_FEAT_DATASINK + datasink_results[0]) as JSON:\n",
    "        datafile = json.load(JSON)\n",
    "        datafile =datafile[0][1][0][1]\n",
    "    datasinkouts = []\n",
    "    datasinkouts += [datafile[i][0] for i in range(len(datafile))]\n",
    "\n",
    "    if Registration:\n",
    "        datasinkouts_afterreg = []\n",
    "        for i in range(len(datasinkouts)):\n",
    "            RESULTS_REG_DATASINK = OUTPUT_DIR + '/tmp/%s_%s/datasink/'%(RegistrationName,i)\n",
    "            Reg_WorkFlow = parallelPreproc.reg_workflow(name = '%s_%s'%(RegistrationName ,i))\n",
    "\n",
    "            Reg_WorkFlow.inputs.inputspec.source_files = datasinkouts[i]\n",
    "            Reg_WorkFlow.inputs.inputspec.anatomical_image = StructuralFiles[i]\n",
    "            Reg_WorkFlow.inputs.inputspec.target_image = ReferenceFile\n",
    "            Reg_WorkFlow.base_dir = TEMP_DIR_FOR_STORAGE\n",
    "            regoutputs = Reg_WorkFlow.run()\n",
    "            datasink_results=[]\n",
    "            datasink_results += [each for each in os.listdir(RESULTS_REG_DATASINK) if each.endswith('.json')]\n",
    "            with open(RESULTS_REG_DATASINK + datasink_results[0]) as JSON:\n",
    "                datafile = json.load(JSON)\n",
    "                datafile = datafile[0][1][0][1]\n",
    "            \n",
    "            datasinkouts_afterreg += [datafile[i][0] for i in range(len(datafile))]\n",
    "            \n",
    "        return datasinkouts_afterreg\n",
    "    else:\n",
    "        return datasinkouts\n",
    "\n",
    "ReferenceFile = AnalysisParams['ReferSummary']['ReferImgPath']\n",
    "ProcessingWay = AnalysisParams['ProcessingType']['ProcessingWay']\n",
    "Ngroups = AnalysisParams['No of Groups']\n",
    "if (ProcessingWay==0):\n",
    "    FunctionaltxtFiles = AnalysisParams['FilesInfo']['FunctionalFilePaths']\n",
    "    StructuraltxtFiles = AnalysisParams['FilesInfo']['StructuralFilePaths']\n",
    "\n",
    "    for i in range(0,Ngroups):\n",
    "        with open(FunctionaltxtFiles[i]) as file:\n",
    "            FunctionalFiles_in_this_group = [line.strip('\\n') for line in file]\n",
    "        with open(StructuraltxtFiles[i]) as file:\n",
    "            StructuralFiles_in_this_group = [line.strip('\\n') for line in file]\n",
    "        Preprocessed_Files = run_Preprocessing(AnalysisParams, FunctionalFiles_in_this_group, StructuralFiles_in_this_group,Group= i)\n",
    "        print(Preprocessed_Files)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(\"Total time taken for running the program: \", stop - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
