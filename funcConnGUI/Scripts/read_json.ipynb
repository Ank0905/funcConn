{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ExtractROI - skip dummy scans\n",
    "'''\n",
    "To be checked whether it has to be used or not. It just skips some scans from the window.\n",
    "'''\n",
    "extract = Node(ExtractROI(t_min=4, t_size=-1),\n",
    "               output_type='NIFTI_GZ',\n",
    "               name=\"extract\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (MotionCorrection==1):\n",
    "    # MCFLIRT - motion correction\n",
    "    mcflirt = Node(MCFLIRT(mean_vol=True,\n",
    "                           save_plots=True,\n",
    "                           output_type='NIFTI_GZ'),\n",
    "                   name=\"mcflirt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Smooth - image smoothing\n",
    "smooth = Node(Smooth(),\n",
    "              fwhm = FWHM,\n",
    "              name=\"smooth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if highpass:\n",
    "#     highpass = Node(interface=fsl.ImageMaths(suffix='_tempfilt'),\n",
    "#                           name='highpass')\n",
    "#     #featpreproc.connect(inputnode, ('highpass', highpass_operand), highpass, 'op_string')\n",
    "#     featpreproc.connect(meanscale, 'out_file', highpass, 'in_file')\n",
    "\n",
    "#     \"\"\"\n",
    "#     Add back the mean removed by the highpass filter operation as of FSL 5.0.7\n",
    "#     \"\"\"\n",
    "#     meanfunc4 = Node(interface=fsl.ImageMaths(op_string='-Tmean',\n",
    "#                                                     suffix='_mean'),\n",
    "#                            name='meanfunc4')\n",
    "\n",
    "#     featpreproc.connect(meanscale, 'out_file', meanfunc4, 'in_file')\n",
    "#     addmean = Node(interface=fsl.BinaryMaths(operation='add'),\n",
    "#                          iterfield=['in_file', 'operand_file'],\n",
    "#                          name='addmean')\n",
    "#     featpreproc.connect(highpass, 'out_file', addmean, 'in_file')\n",
    "#     featpreproc.connect(meanfunc4, 'out_file', addmean, 'operand_file')\n",
    "#     featpreproc.connect(addmean, 'out_file', outputnode, 'highpassed_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "art = Node(ArtifactDetect(norm_threshold=2,\n",
    "                          zintensity_threshold=3,\n",
    "                          mask_type='spm_global',\n",
    "                          parameter_source='FSL',\n",
    "                          use_differences=[True, False],\n",
    "                          plot_type='svg'),\n",
    "           name=\"art\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['func', 'anat']),\n",
    "                  name=\"infosource\")\n",
    "\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory=experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "## Use the following DataSink output substitutions\n",
    "substitutions = [('_subject_id_', ''),\n",
    "                 ('_task_name_', '/task-'),\n",
    "                 ('_fwhm_', 'fwhm-'),\n",
    "                 ('_roi', ''),\n",
    "                 ('_mcf', ''),\n",
    "                 ('_st', ''),\n",
    "                 ('_flirt', ''),\n",
    "                 ('.nii_mean_reg', '_mean'),\n",
    "                 ('.nii.par', '.par'),\n",
    "                 ]\n",
    "\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a preprocessing workflow\n",
    "preproc = Workflow(name='preproc')\n",
    "preproc.base_dir = opj(experiment_dir, working_dir)\n",
    "\n",
    "# Connect all components of the preprocessing workflow\n",
    "preproc.connect([(infosource, extract, [('func', 'in_file')]),\n",
    "                 (extract, mcflirt, [('roi_file', 'in_file')]),\n",
    "                 (mcflirt, slicetimer, [('out_file', 'in_file')]),\n",
    "\n",
    "                 (infosource, coregwf, [('anat', 'bet_anat.in_file'),\n",
    "                                         ('anat', 'coreg_bbr.reference')]),\n",
    "                 (mcflirt, coregwf, [('mean_img', 'coreg_pre.in_file'),\n",
    "                                     ('mean_img', 'coreg_bbr.in_file'),\n",
    "                                     ('mean_img', 'applywarp_mean.in_file')]),\n",
    "                 (slicetimer, coregwf, [('slice_time_corrected_file', 'applywarp.in_file')]),\n",
    "                 \n",
    "                 (coregwf, smooth, [('applywarp.out_file', 'in_files')]),\n",
    "#                 (inputnode, highpass,[(('highpass', highpass_operand), 'op_string')]),\n",
    "                 (mcflirt, datasink, [('par_file', 'preproc.@par')]),\n",
    "                 (smooth, datasink, [('smoothed_files', 'preproc.@smooth')]),\n",
    "                 \n",
    "                 (coregwf, datasink, [('applywarp_mean.out_file', 'preproc.@mean')]),\n",
    "\n",
    "                 (coregwf, art, [('applywarp.out_file', 'realigned_files')]),\n",
    "                 (mcflirt, art, [('par_file', 'realignment_parameters')]),\n",
    "\n",
    "                 (coregwf, datasink, [('coreg_bbr.out_matrix_file', 'preproc.@mat_file'),\n",
    "                                      ('bet_anat.out_file', 'preproc.@brain')]),\n",
    "                 (art, datasink, [('outlier_files', 'preproc.@outlier_files'),\n",
    "                                  ('plot_files', 'preproc.@plot_files')]),\n",
    "                 ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create preproc output graph\n",
    "preproc.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename=opj(preproc.base_dir, 'preproc', 'graph.dot.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the detailed graph\n",
    "preproc.write_graph(graph2use='flat', format='png', simple_form=True)\n",
    "Image(filename=opj(preproc.base_dir, 'preproc', 'graph_detailed.dot.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = fsl.ImageStats(op_string='-k %s -p 50', in_file = \"/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3577037/session_1/rest_1/rest_linearMNI3mm.nii.gz\",\n",
    "                   mask_file = \"/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3577037/session_1/rest_1/rest_linearMNI3mm.nii.gz\")\n",
    "ab.cmdline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170928-15:51:48,52 workflow INFO:\n",
      "\t Generated workflow graph: /home/deepak/Desktop/FConnectivityAnalysis/tmp/featpreproc/graph.dot.png (graph2use=colored, simple_form=True).\n",
      "170928-15:51:48,96 workflow INFO:\n",
      "\t Workflow featpreproc settings: ['check', 'execution', 'logging']\n",
      "170928-15:51:48,118 workflow INFO:\n",
      "\t Running in parallel.\n",
      "170928-15:51:48,122 workflow INFO:\n",
      "\t Executing: img2float ID: 0\n",
      "170928-15:51:48,128 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode img2float\n",
      "170928-15:51:48,134 workflow INFO:\n",
      "\t Executing: _img2float0 ID: 25\n",
      "170928-15:51:48,136 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float0 jobid: 25\n",
      "170928-15:51:48,137 workflow INFO:\n",
      "\t Executing: _img2float1 ID: 26\n",
      "170928-15:51:48,139 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float1 jobid: 26\n",
      "170928-15:51:48,140 workflow INFO:\n",
      "\t Executing: _img2float2 ID: 27\n",
      "170928-15:51:48,142 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float2 jobid: 27\n",
      "170928-15:51:48,143 workflow INFO:\n",
      "\t Executing: _img2float3 ID: 28\n",
      "170928-15:51:48,145 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float3 jobid: 28\n",
      "170928-15:51:48,147 workflow INFO:\n",
      "\t Executing: _img2float4 ID: 29\n",
      "170928-15:51:48,149 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float4 jobid: 29\n",
      "170928-15:51:48,150 workflow INFO:\n",
      "\t Executing: _img2float5 ID: 30\n",
      "170928-15:51:48,151 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float5 jobid: 30\n",
      "170928-15:51:48,152 workflow INFO:\n",
      "\t Executing: _img2float6 ID: 31\n",
      "170928-15:51:48,154 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float6 jobid: 31\n",
      "170928-15:51:48,155 workflow INFO:\n",
      "\t Executing: _img2float7 ID: 32\n",
      "170928-15:51:48,156 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float7 jobid: 32\n",
      "170928-15:51:48,158 workflow INFO:\n",
      "\t Executing: _img2float8 ID: 33\n",
      "170928-15:51:48,160 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float8 jobid: 33\n",
      "170928-15:51:48,162 workflow INFO:\n",
      "\t Executing: _img2float9 ID: 34\n",
      "170928-15:51:48,164 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float9 jobid: 34\n",
      "170928-15:51:48,165 workflow INFO:\n",
      "\t Executing: _img2float10 ID: 35\n",
      "170928-15:51:48,167 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float10 jobid: 35\n",
      "170928-15:51:48,168 workflow INFO:\n",
      "\t Executing: _img2float11 ID: 36\n",
      "170928-15:51:48,170 workflow INFO:\n",
      "\t [Job finished] jobname: _img2float11 jobid: 36\n",
      "170928-15:51:48,172 workflow INFO:\n",
      "\t Executing: img2float ID: 0\n",
      "170928-15:51:48,175 workflow INFO:\n",
      "\t [Job finished] jobname: img2float jobid: 0\n",
      "170928-15:51:48,178 workflow INFO:\n",
      "\t Executing: extractref ID: 1\n",
      "170928-15:51:48,193 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode extractref\n",
      "170928-15:51:48,199 workflow INFO:\n",
      "\t Executing: _extractref0 ID: 37\n",
      "170928-15:51:48,201 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref0 jobid: 37\n",
      "170928-15:51:48,203 workflow INFO:\n",
      "\t Executing: _extractref1 ID: 38\n",
      "170928-15:51:48,204 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref1 jobid: 38\n",
      "170928-15:51:48,205 workflow INFO:\n",
      "\t Executing: _extractref2 ID: 39\n",
      "170928-15:51:48,207 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref2 jobid: 39\n",
      "170928-15:51:48,208 workflow INFO:\n",
      "\t Executing: _extractref3 ID: 40\n",
      "170928-15:51:48,209 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref3 jobid: 40\n",
      "170928-15:51:48,213 workflow INFO:\n",
      "\t Executing: _extractref4 ID: 41\n",
      "170928-15:51:48,214 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref4 jobid: 41\n",
      "170928-15:51:48,215 workflow INFO:\n",
      "\t Executing: _extractref5 ID: 42\n",
      "170928-15:51:48,217 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref5 jobid: 42\n",
      "170928-15:51:48,218 workflow INFO:\n",
      "\t Executing: _extractref6 ID: 43\n",
      "170928-15:51:48,219 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref6 jobid: 43\n",
      "170928-15:51:48,220 workflow INFO:\n",
      "\t Executing: _extractref7 ID: 44\n",
      "170928-15:51:48,222 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref7 jobid: 44\n",
      "170928-15:51:48,224 workflow INFO:\n",
      "\t Executing: _extractref8 ID: 45\n",
      "170928-15:51:48,226 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref8 jobid: 45\n",
      "170928-15:51:48,227 workflow INFO:\n",
      "\t Executing: _extractref9 ID: 46\n",
      "170928-15:51:48,228 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref9 jobid: 46\n",
      "170928-15:51:48,229 workflow INFO:\n",
      "\t Executing: _extractref10 ID: 47\n",
      "170928-15:51:48,230 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref10 jobid: 47\n",
      "170928-15:51:48,231 workflow INFO:\n",
      "\t Executing: _extractref11 ID: 48\n",
      "170928-15:51:48,232 workflow INFO:\n",
      "\t [Job finished] jobname: _extractref11 jobid: 48\n",
      "170928-15:51:48,234 workflow INFO:\n",
      "\t Executing: extractref ID: 1\n",
      "170928-15:51:48,237 workflow INFO:\n",
      "\t [Job finished] jobname: extractref jobid: 1\n",
      "170928-15:51:48,239 workflow INFO:\n",
      "\t Executing: realign ID: 2\n",
      "170928-15:51:48,248 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode realign\n",
      "170928-15:51:48,253 workflow INFO:\n",
      "\t Executing: _realign0 ID: 49\n",
      "170928-15:51:48,254 workflow INFO:\n",
      "\t [Job finished] jobname: _realign0 jobid: 49\n",
      "170928-15:51:48,255 workflow INFO:\n",
      "\t Executing: _realign1 ID: 50\n",
      "170928-15:51:48,256 workflow INFO:\n",
      "\t [Job finished] jobname: _realign1 jobid: 50\n",
      "170928-15:51:48,257 workflow INFO:\n",
      "\t Executing: _realign2 ID: 51\n",
      "170928-15:51:48,258 workflow INFO:\n",
      "\t [Job finished] jobname: _realign2 jobid: 51\n",
      "170928-15:51:48,259 workflow INFO:\n",
      "\t Executing: _realign3 ID: 52\n",
      "170928-15:51:48,260 workflow INFO:\n",
      "\t [Job finished] jobname: _realign3 jobid: 52\n",
      "170928-15:51:48,264 workflow INFO:\n",
      "\t Executing: _realign4 ID: 53\n",
      "170928-15:51:48,265 workflow INFO:\n",
      "\t [Job finished] jobname: _realign4 jobid: 53\n",
      "170928-15:51:48,266 workflow INFO:\n",
      "\t Executing: _realign5 ID: 54\n",
      "170928-15:51:48,268 workflow INFO:\n",
      "\t [Job finished] jobname: _realign5 jobid: 54\n",
      "170928-15:51:48,269 workflow INFO:\n",
      "\t Executing: _realign6 ID: 55\n",
      "170928-15:51:48,270 workflow INFO:\n",
      "\t [Job finished] jobname: _realign6 jobid: 55\n",
      "170928-15:51:48,271 workflow INFO:\n",
      "\t Executing: _realign7 ID: 56\n",
      "170928-15:51:48,272 workflow INFO:\n",
      "\t [Job finished] jobname: _realign7 jobid: 56\n",
      "170928-15:51:48,274 workflow INFO:\n",
      "\t Executing: _realign8 ID: 57\n",
      "170928-15:51:48,276 workflow INFO:\n",
      "\t [Job finished] jobname: _realign8 jobid: 57\n",
      "170928-15:51:48,277 workflow INFO:\n",
      "\t Executing: _realign9 ID: 58\n",
      "170928-15:51:48,278 workflow INFO:\n",
      "\t [Job finished] jobname: _realign9 jobid: 58\n",
      "170928-15:51:48,280 workflow INFO:\n",
      "\t Executing: _realign10 ID: 59\n",
      "170928-15:51:48,281 workflow INFO:\n",
      "\t [Job finished] jobname: _realign10 jobid: 59\n",
      "170928-15:51:48,282 workflow INFO:\n",
      "\t Executing: _realign11 ID: 60\n",
      "170928-15:51:48,283 workflow INFO:\n",
      "\t [Job finished] jobname: _realign11 jobid: 60\n",
      "170928-15:51:48,286 workflow INFO:\n",
      "\t Executing: realign ID: 2\n",
      "170928-15:51:48,288 workflow INFO:\n",
      "\t [Job finished] jobname: realign jobid: 2\n",
      "170928-15:51:48,291 workflow INFO:\n",
      "\t Executing: slicetimer ID: 3\n",
      "170928-15:51:48,298 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode slicetimer\n",
      "170928-15:51:48,301 workflow INFO:\n",
      "\t Executing: plot_motion.aI.a0 ID: 23\n",
      "170928-15:51:48,317 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode plot_motion.aI.a0\n",
      "170928-15:51:48,321 workflow INFO:\n",
      "\t Executing: plot_motion.aI.a1 ID: 24\n",
      "170928-15:51:48,327 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode plot_motion.aI.a1\n",
      "170928-15:51:48,332 workflow INFO:\n",
      "\t Executing: _slicetimer0 ID: 61\n",
      "170928-15:51:48,334 workflow INFO:\n",
      "\t [Job finished] jobname: _slicetimer0 jobid: 61\n",
      "170928-15:51:48,335 workflow INFO:\n",
      "\t Executing: _slicetimer1 ID: 62\n",
      "170928-15:51:48,336 workflow INFO:\n",
      "\t [Job finished] jobname: _slicetimer1 jobid: 62\n",
      "170928-15:51:48,337 workflow INFO:\n",
      "\t Executing: _slicetimer2 ID: 63\n",
      "170928-15:51:48,338 workflow INFO:\n",
      "\t [Job finished] jobname: _slicetimer2 jobid: 63\n",
      "170928-15:51:48,339 workflow INFO:\n",
      "\t Executing: _slicetimer3 ID: 64\n",
      "170928-15:51:48,341 workflow INFO:\n",
      "\t [Job finished] jobname: _slicetimer3 jobid: 64\n",
      "170928-15:51:48,344 workflow INFO:\n",
      "\t Executing: _slicetimer4 ID: 65\n",
      "170928-15:51:48,346 workflow INFO:\n",
      "\t [Job finished] jobname: _slicetimer4 jobid: 65\n",
      "170928-15:51:48,347 workflow INFO:\n",
      "\t Executing: _slicetimer5 ID: 66\n",
      "170928-15:51:48,348 workflow INFO:\n",
      "\t [Job finished] jobname: _slicetimer5 jobid: 66\n",
      "170928-15:51:48,349 workflow INFO:\n",
      "\t Executing: _slicetimer6 ID: 67\n",
      "170928-15:51:48,350 workflow INFO:\n",
      "\t [Job finished] jobname: _slicetimer6 jobid: 67\n",
      "170928-15:51:48,351 workflow INFO:\n",
      "\t Executing: _slicetimer7 ID: 68\n",
      "170928-15:51:48,352 workflow INFO:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Job finished] jobname: _slicetimer7 jobid: 68\n",
      "170928-15:51:48,355 workflow INFO:\n",
      "\t Executing: _slicetimer8 ID: 69\n",
      "170928-15:51:48,356 workflow INFO:\n",
      "\t [Job finished] jobname: _slicetimer8 jobid: 69\n",
      "170928-15:51:48,357 workflow INFO:\n",
      "\t Executing: _slicetimer9 ID: 70\n",
      "170928-15:51:48,359 workflow INFO:\n",
      "\t [Job finished] jobname: _slicetimer9 jobid: 70\n",
      "170928-15:51:48,360 workflow INFO:\n",
      "\t Executing: _slicetimer10 ID: 71\n",
      "170928-15:51:48,361 workflow INFO:\n",
      "\t [Job finished] jobname: _slicetimer10 jobid: 71\n",
      "170928-15:51:48,362 workflow INFO:\n",
      "\t Executing: _slicetimer11 ID: 72\n",
      "170928-15:51:48,364 workflow INFO:\n",
      "\t [Job finished] jobname: _slicetimer11 jobid: 72\n",
      "170928-15:51:48,366 workflow INFO:\n",
      "\t Executing: slicetimer ID: 3\n",
      "170928-15:51:48,368 workflow INFO:\n",
      "\t [Job finished] jobname: slicetimer jobid: 3\n",
      "170928-15:51:48,369 workflow INFO:\n",
      "\t Executing: _plot_motion0 ID: 73\n",
      "170928-15:51:48,370 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion0 jobid: 73\n",
      "170928-15:51:48,371 workflow INFO:\n",
      "\t Executing: _plot_motion1 ID: 74\n",
      "170928-15:51:48,373 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion1 jobid: 74\n",
      "170928-15:51:48,374 workflow INFO:\n",
      "\t Executing: _plot_motion2 ID: 75\n",
      "170928-15:51:48,375 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion2 jobid: 75\n",
      "170928-15:51:48,378 workflow INFO:\n",
      "\t Executing: meanfunc ID: 4\n",
      "170928-15:51:48,385 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode meanfunc\n",
      "170928-15:51:48,388 workflow INFO:\n",
      "\t Executing: _plot_motion3 ID: 76\n",
      "170928-15:51:48,390 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion3 jobid: 76\n",
      "170928-15:51:48,390 workflow INFO:\n",
      "\t Executing: _plot_motion4 ID: 77\n",
      "170928-15:51:48,392 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion4 jobid: 77\n",
      "170928-15:51:48,393 workflow INFO:\n",
      "\t Executing: _plot_motion5 ID: 78\n",
      "170928-15:51:48,394 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion5 jobid: 78\n",
      "170928-15:51:48,395 workflow INFO:\n",
      "\t Executing: _plot_motion6 ID: 79\n",
      "170928-15:51:48,396 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion6 jobid: 79\n",
      "170928-15:51:48,398 workflow INFO:\n",
      "\t Executing: _plot_motion7 ID: 80\n",
      "170928-15:51:48,400 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion7 jobid: 80\n",
      "170928-15:51:48,401 workflow INFO:\n",
      "\t Executing: _plot_motion8 ID: 81\n",
      "170928-15:51:48,402 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion8 jobid: 81\n",
      "170928-15:51:48,403 workflow INFO:\n",
      "\t Executing: _plot_motion9 ID: 82\n",
      "170928-15:51:48,404 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion9 jobid: 82\n",
      "170928-15:51:48,405 workflow INFO:\n",
      "\t Executing: _plot_motion10 ID: 83\n",
      "170928-15:51:48,407 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion10 jobid: 83\n",
      "170928-15:51:48,410 workflow INFO:\n",
      "\t Executing: _plot_motion11 ID: 84\n",
      "170928-15:51:48,411 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion11 jobid: 84\n",
      "170928-15:51:48,413 workflow INFO:\n",
      "\t Executing: _plot_motion0 ID: 85\n",
      "170928-15:51:48,415 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion0 jobid: 85\n",
      "170928-15:51:48,416 workflow INFO:\n",
      "\t Executing: _plot_motion1 ID: 86\n",
      "170928-15:51:48,419 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion1 jobid: 86\n",
      "170928-15:51:48,420 workflow INFO:\n",
      "\t Executing: _plot_motion2 ID: 87\n",
      "170928-15:51:48,421 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion2 jobid: 87\n",
      "170928-15:51:48,424 workflow INFO:\n",
      "\t Executing: plot_motion.aI.a0 ID: 23\n",
      "170928-15:51:48,427 workflow INFO:\n",
      "\t [Job finished] jobname: plot_motion.aI.a0 jobid: 23\n",
      "170928-15:51:48,428 workflow INFO:\n",
      "\t Executing: _plot_motion3 ID: 88\n",
      "170928-15:51:48,432 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion3 jobid: 88\n",
      "170928-15:51:48,433 workflow INFO:\n",
      "\t Executing: _plot_motion4 ID: 89\n",
      "170928-15:51:48,435 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion4 jobid: 89\n",
      "170928-15:51:48,436 workflow INFO:\n",
      "\t Executing: _plot_motion5 ID: 90\n",
      "170928-15:51:48,437 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion5 jobid: 90\n",
      "170928-15:51:48,441 workflow INFO:\n",
      "\t Executing: _plot_motion6 ID: 91\n",
      "170928-15:51:48,442 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion6 jobid: 91\n",
      "170928-15:51:48,443 workflow INFO:\n",
      "\t Executing: _plot_motion7 ID: 92\n",
      "170928-15:51:48,444 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion7 jobid: 92\n",
      "170928-15:51:48,446 workflow INFO:\n",
      "\t Executing: _plot_motion8 ID: 93\n",
      "170928-15:51:48,448 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion8 jobid: 93\n",
      "170928-15:51:48,449 workflow INFO:\n",
      "\t Executing: _plot_motion9 ID: 94\n",
      "170928-15:51:48,451 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion9 jobid: 94\n",
      "170928-15:51:48,454 workflow INFO:\n",
      "\t Executing: _plot_motion10 ID: 95\n",
      "170928-15:51:48,457 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion10 jobid: 95\n",
      "170928-15:51:48,458 workflow INFO:\n",
      "\t Executing: _plot_motion11 ID: 96\n",
      "170928-15:51:48,460 workflow INFO:\n",
      "\t [Job finished] jobname: _plot_motion11 jobid: 96\n",
      "170928-15:51:48,462 workflow INFO:\n",
      "\t Executing: _meanfunc0 ID: 97\n",
      "170928-15:51:48,463 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc0 jobid: 97\n",
      "170928-15:51:48,465 workflow INFO:\n",
      "\t Executing: _meanfunc1 ID: 98\n",
      "170928-15:51:48,467 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc1 jobid: 98\n",
      "170928-15:51:48,469 workflow INFO:\n",
      "\t Executing: plot_motion.aI.a1 ID: 24\n",
      "170928-15:51:48,472 workflow INFO:\n",
      "\t [Job finished] jobname: plot_motion.aI.a1 jobid: 24\n",
      "170928-15:51:48,473 workflow INFO:\n",
      "\t Executing: _meanfunc2 ID: 99\n",
      "170928-15:51:48,475 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc2 jobid: 99\n",
      "170928-15:51:48,476 workflow INFO:\n",
      "\t Executing: _meanfunc3 ID: 100\n",
      "170928-15:51:48,478 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc3 jobid: 100\n",
      "170928-15:51:48,480 workflow INFO:\n",
      "\t Executing: _meanfunc4 ID: 101\n",
      "170928-15:51:48,482 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc4 jobid: 101\n",
      "170928-15:51:48,485 workflow INFO:\n",
      "\t Executing: _meanfunc5 ID: 102\n",
      "170928-15:51:48,487 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc5 jobid: 102\n",
      "170928-15:51:48,488 workflow INFO:\n",
      "\t Executing: _meanfunc6 ID: 103\n",
      "170928-15:51:48,489 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc6 jobid: 103\n",
      "170928-15:51:48,490 workflow INFO:\n",
      "\t Executing: _meanfunc7 ID: 104\n",
      "170928-15:51:48,492 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc7 jobid: 104\n",
      "170928-15:51:48,493 workflow INFO:\n",
      "\t Executing: _meanfunc8 ID: 105\n",
      "170928-15:51:48,494 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc8 jobid: 105\n",
      "170928-15:51:48,496 workflow INFO:\n",
      "\t Executing: _meanfunc9 ID: 106\n",
      "170928-15:51:48,498 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc9 jobid: 106\n",
      "170928-15:51:48,499 workflow INFO:\n",
      "\t Executing: _meanfunc10 ID: 107\n",
      "170928-15:51:48,501 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc10 jobid: 107\n",
      "170928-15:51:48,503 workflow INFO:\n",
      "\t Executing: _meanfunc11 ID: 108\n",
      "170928-15:51:48,504 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc11 jobid: 108\n",
      "170928-15:51:48,508 workflow INFO:\n",
      "\t Executing: meanfunc ID: 4\n",
      "170928-15:51:48,510 workflow INFO:\n",
      "\t [Job finished] jobname: meanfunc jobid: 4\n",
      "170928-15:51:48,513 workflow INFO:\n",
      "\t Executing: meanfuncmask ID: 5\n",
      "170928-15:51:48,521 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode meanfuncmask\n",
      "170928-15:51:48,527 workflow INFO:\n",
      "\t Executing: _meanfuncmask0 ID: 109\n",
      "170928-15:51:48,528 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask0 jobid: 109\n",
      "170928-15:51:48,529 workflow INFO:\n",
      "\t Executing: _meanfuncmask1 ID: 110\n",
      "170928-15:51:48,531 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask1 jobid: 110\n",
      "170928-15:51:48,532 workflow INFO:\n",
      "\t Executing: _meanfuncmask2 ID: 111\n",
      "170928-15:51:48,533 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask2 jobid: 111\n",
      "170928-15:51:48,534 workflow INFO:\n",
      "\t Executing: _meanfuncmask3 ID: 112\n",
      "170928-15:51:48,539 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask3 jobid: 112\n",
      "170928-15:51:48,541 workflow INFO:\n",
      "\t Executing: _meanfuncmask4 ID: 113\n",
      "170928-15:51:48,543 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask4 jobid: 113\n",
      "170928-15:51:48,544 workflow INFO:\n",
      "\t Executing: _meanfuncmask5 ID: 114\n",
      "170928-15:51:48,546 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask5 jobid: 114\n",
      "170928-15:51:48,548 workflow INFO:\n",
      "\t Executing: _meanfuncmask6 ID: 115\n",
      "170928-15:51:48,552 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask6 jobid: 115\n",
      "170928-15:51:48,553 workflow INFO:\n",
      "\t Executing: _meanfuncmask7 ID: 116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170928-15:51:48,556 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask7 jobid: 116\n",
      "170928-15:51:48,559 workflow INFO:\n",
      "\t Executing: _meanfuncmask8 ID: 117\n",
      "170928-15:51:48,561 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask8 jobid: 117\n",
      "170928-15:51:48,564 workflow INFO:\n",
      "\t Executing: _meanfuncmask9 ID: 118\n",
      "170928-15:51:48,565 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask9 jobid: 118\n",
      "170928-15:51:48,567 workflow INFO:\n",
      "\t Executing: _meanfuncmask10 ID: 119\n",
      "170928-15:51:48,569 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask10 jobid: 119\n",
      "170928-15:51:48,570 workflow INFO:\n",
      "\t Executing: _meanfuncmask11 ID: 120\n",
      "170928-15:51:48,572 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfuncmask11 jobid: 120\n",
      "170928-15:51:48,574 workflow INFO:\n",
      "\t Executing: meanfuncmask ID: 5\n",
      "170928-15:51:48,576 workflow INFO:\n",
      "\t [Job finished] jobname: meanfuncmask jobid: 5\n",
      "170928-15:51:48,579 workflow INFO:\n",
      "\t Executing: maskfunc ID: 6\n",
      "170928-15:51:48,588 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode maskfunc\n",
      "170928-15:51:48,595 workflow INFO:\n",
      "\t Executing: _maskfunc0 ID: 121\n",
      "170928-15:51:48,597 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc0 jobid: 121\n",
      "170928-15:51:48,599 workflow INFO:\n",
      "\t Executing: _maskfunc1 ID: 122\n",
      "170928-15:51:48,601 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc1 jobid: 122\n",
      "170928-15:51:48,603 workflow INFO:\n",
      "\t Executing: _maskfunc2 ID: 123\n",
      "170928-15:51:48,606 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc2 jobid: 123\n",
      "170928-15:51:48,607 workflow INFO:\n",
      "\t Executing: _maskfunc3 ID: 124\n",
      "170928-15:51:48,609 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc3 jobid: 124\n",
      "170928-15:51:48,613 workflow INFO:\n",
      "\t Executing: _maskfunc4 ID: 125\n",
      "170928-15:51:48,615 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc4 jobid: 125\n",
      "170928-15:51:48,617 workflow INFO:\n",
      "\t Executing: _maskfunc5 ID: 126\n",
      "170928-15:51:48,619 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc5 jobid: 126\n",
      "170928-15:51:48,620 workflow INFO:\n",
      "\t Executing: _maskfunc6 ID: 127\n",
      "170928-15:51:48,622 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc6 jobid: 127\n",
      "170928-15:51:48,624 workflow INFO:\n",
      "\t Executing: _maskfunc7 ID: 128\n",
      "170928-15:51:48,626 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc7 jobid: 128\n",
      "170928-15:51:48,630 workflow INFO:\n",
      "\t Executing: _maskfunc8 ID: 129\n",
      "170928-15:51:48,631 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc8 jobid: 129\n",
      "170928-15:51:48,633 workflow INFO:\n",
      "\t Executing: _maskfunc9 ID: 130\n",
      "170928-15:51:48,634 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc9 jobid: 130\n",
      "170928-15:51:48,635 workflow INFO:\n",
      "\t Executing: _maskfunc10 ID: 131\n",
      "170928-15:51:48,637 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc10 jobid: 131\n",
      "170928-15:51:48,638 workflow INFO:\n",
      "\t Executing: _maskfunc11 ID: 132\n",
      "170928-15:51:48,640 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc11 jobid: 132\n",
      "170928-15:51:48,643 workflow INFO:\n",
      "\t Executing: maskfunc ID: 6\n",
      "170928-15:51:48,646 workflow INFO:\n",
      "\t [Job finished] jobname: maskfunc jobid: 6\n",
      "170928-15:51:48,649 workflow INFO:\n",
      "\t Executing: getthreshold ID: 7\n",
      "170928-15:51:48,657 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode getthreshold\n",
      "170928-15:51:48,666 workflow INFO:\n",
      "\t Executing: _getthreshold0 ID: 133\n",
      "170928-15:51:48,668 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold0 jobid: 133\n",
      "170928-15:51:48,670 workflow INFO:\n",
      "\t Executing: _getthreshold1 ID: 134\n",
      "170928-15:51:48,673 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold1 jobid: 134\n",
      "170928-15:51:48,674 workflow INFO:\n",
      "\t Executing: _getthreshold2 ID: 135\n",
      "170928-15:51:48,675 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold2 jobid: 135\n",
      "170928-15:51:48,678 workflow INFO:\n",
      "\t Executing: _getthreshold3 ID: 136\n",
      "170928-15:51:48,679 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold3 jobid: 136\n",
      "170928-15:51:48,683 workflow INFO:\n",
      "\t Executing: _getthreshold4 ID: 137\n",
      "170928-15:51:48,685 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold4 jobid: 137\n",
      "170928-15:51:48,687 workflow INFO:\n",
      "\t Executing: _getthreshold5 ID: 138\n",
      "170928-15:51:48,689 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold5 jobid: 138\n",
      "170928-15:51:48,690 workflow INFO:\n",
      "\t Executing: _getthreshold6 ID: 139\n",
      "170928-15:51:48,692 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold6 jobid: 139\n",
      "170928-15:51:48,693 workflow INFO:\n",
      "\t Executing: _getthreshold7 ID: 140\n",
      "170928-15:51:48,694 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold7 jobid: 140\n",
      "170928-15:51:48,697 workflow INFO:\n",
      "\t Executing: _getthreshold8 ID: 141\n",
      "170928-15:51:48,698 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold8 jobid: 141\n",
      "170928-15:51:48,699 workflow INFO:\n",
      "\t Executing: _getthreshold9 ID: 142\n",
      "170928-15:51:48,701 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold9 jobid: 142\n",
      "170928-15:51:48,702 workflow INFO:\n",
      "\t Executing: _getthreshold10 ID: 143\n",
      "170928-15:51:48,705 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold10 jobid: 143\n",
      "170928-15:51:48,706 workflow INFO:\n",
      "\t Executing: _getthreshold11 ID: 144\n",
      "170928-15:51:48,708 workflow INFO:\n",
      "\t [Job finished] jobname: _getthreshold11 jobid: 144\n",
      "170928-15:51:48,712 workflow INFO:\n",
      "\t Executing: getthreshold ID: 7\n",
      "170928-15:51:48,715 workflow INFO:\n",
      "\t [Job finished] jobname: getthreshold jobid: 7\n",
      "170928-15:51:48,718 workflow INFO:\n",
      "\t Executing: threshold ID: 8\n",
      "170928-15:51:48,727 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode threshold\n",
      "170928-15:51:48,735 workflow INFO:\n",
      "\t Executing: _threshold0 ID: 145\n",
      "170928-15:51:48,736 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold0 jobid: 145\n",
      "170928-15:51:48,737 workflow INFO:\n",
      "\t Executing: _threshold1 ID: 146\n",
      "170928-15:51:48,739 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold1 jobid: 146\n",
      "170928-15:51:48,740 workflow INFO:\n",
      "\t Executing: _threshold2 ID: 147\n",
      "170928-15:51:48,742 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold2 jobid: 147\n",
      "170928-15:51:48,743 workflow INFO:\n",
      "\t Executing: _threshold3 ID: 148\n",
      "170928-15:51:48,744 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold3 jobid: 148\n",
      "170928-15:51:48,747 workflow INFO:\n",
      "\t Executing: _threshold4 ID: 149\n",
      "170928-15:51:48,749 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold4 jobid: 149\n",
      "170928-15:51:48,751 workflow INFO:\n",
      "\t Executing: _threshold5 ID: 150\n",
      "170928-15:51:48,753 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold5 jobid: 150\n",
      "170928-15:51:48,754 workflow INFO:\n",
      "\t Executing: _threshold6 ID: 151\n",
      "170928-15:51:48,756 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold6 jobid: 151\n",
      "170928-15:51:48,757 workflow INFO:\n",
      "\t Executing: _threshold7 ID: 152\n",
      "170928-15:51:48,758 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold7 jobid: 152\n",
      "170928-15:51:48,761 workflow INFO:\n",
      "\t Executing: _threshold8 ID: 153\n",
      "170928-15:51:48,762 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold8 jobid: 153\n",
      "170928-15:51:48,764 workflow INFO:\n",
      "\t Executing: _threshold9 ID: 154\n",
      "170928-15:51:48,765 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold9 jobid: 154\n",
      "170928-15:51:48,768 workflow INFO:\n",
      "\t Executing: _threshold10 ID: 155\n",
      "170928-15:51:48,770 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold10 jobid: 155\n",
      "170928-15:51:48,772 workflow INFO:\n",
      "\t Executing: _threshold11 ID: 156\n",
      "170928-15:51:48,774 workflow INFO:\n",
      "\t [Job finished] jobname: _threshold11 jobid: 156\n",
      "170928-15:51:48,778 workflow INFO:\n",
      "\t Executing: threshold ID: 8\n",
      "170928-15:51:48,781 workflow INFO:\n",
      "\t [Job finished] jobname: threshold jobid: 8\n",
      "170928-15:51:48,785 workflow INFO:\n",
      "\t Executing: dilatemask ID: 9\n",
      "170928-15:51:48,791 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode dilatemask\n",
      "170928-15:51:48,796 workflow INFO:\n",
      "\t Executing: medianval ID: 10\n",
      "170928-15:51:48,804 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode medianval\n",
      "170928-15:51:48,811 workflow INFO:\n",
      "\t Executing: _dilatemask0 ID: 157\n",
      "170928-15:51:48,814 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask0 jobid: 157\n",
      "170928-15:51:48,815 workflow INFO:\n",
      "\t Executing: _dilatemask1 ID: 158\n",
      "170928-15:51:48,818 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask1 jobid: 158\n",
      "170928-15:51:48,819 workflow INFO:\n",
      "\t Executing: _dilatemask2 ID: 159\n",
      "170928-15:51:48,821 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask2 jobid: 159\n",
      "170928-15:51:48,822 workflow INFO:\n",
      "\t Executing: _dilatemask3 ID: 160\n",
      "170928-15:51:48,824 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask3 jobid: 160\n",
      "170928-15:51:48,827 workflow INFO:\n",
      "\t Executing: _dilatemask4 ID: 161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170928-15:51:48,829 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask4 jobid: 161\n",
      "170928-15:51:48,830 workflow INFO:\n",
      "\t Executing: _dilatemask5 ID: 162\n",
      "170928-15:51:48,831 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask5 jobid: 162\n",
      "170928-15:51:48,832 workflow INFO:\n",
      "\t Executing: _dilatemask6 ID: 163\n",
      "170928-15:51:48,833 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask6 jobid: 163\n",
      "170928-15:51:48,834 workflow INFO:\n",
      "\t Executing: _dilatemask7 ID: 164\n",
      "170928-15:51:48,836 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask7 jobid: 164\n",
      "170928-15:51:48,839 workflow INFO:\n",
      "\t Executing: _dilatemask8 ID: 165\n",
      "170928-15:51:48,840 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask8 jobid: 165\n",
      "170928-15:51:48,841 workflow INFO:\n",
      "\t Executing: _dilatemask9 ID: 166\n",
      "170928-15:51:48,842 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask9 jobid: 166\n",
      "170928-15:51:48,843 workflow INFO:\n",
      "\t Executing: _dilatemask10 ID: 167\n",
      "170928-15:51:48,844 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask10 jobid: 167\n",
      "170928-15:51:48,845 workflow INFO:\n",
      "\t Executing: _dilatemask11 ID: 168\n",
      "170928-15:51:48,846 workflow INFO:\n",
      "\t [Job finished] jobname: _dilatemask11 jobid: 168\n",
      "170928-15:51:48,851 workflow INFO:\n",
      "\t Executing: dilatemask ID: 9\n",
      "170928-15:51:48,853 workflow INFO:\n",
      "\t [Job finished] jobname: dilatemask jobid: 9\n",
      "170928-15:51:48,855 workflow INFO:\n",
      "\t Executing: _medianval0 ID: 169\n",
      "170928-15:51:48,855 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval0 jobid: 169\n",
      "170928-15:51:48,856 workflow INFO:\n",
      "\t Executing: _medianval1 ID: 170\n",
      "170928-15:51:48,858 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval1 jobid: 170\n",
      "170928-15:51:48,859 workflow INFO:\n",
      "\t Executing: _medianval2 ID: 171\n",
      "170928-15:51:48,860 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval2 jobid: 171\n",
      "170928-15:51:48,863 workflow INFO:\n",
      "\t Executing: maskfunc2 ID: 11\n",
      "170928-15:51:48,873 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode maskfunc2\n",
      "170928-15:51:48,877 workflow INFO:\n",
      "\t Executing: _medianval3 ID: 172\n",
      "170928-15:51:48,879 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval3 jobid: 172\n",
      "170928-15:51:48,880 workflow INFO:\n",
      "\t Executing: _medianval4 ID: 173\n",
      "170928-15:51:48,881 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval4 jobid: 173\n",
      "170928-15:51:48,882 workflow INFO:\n",
      "\t Executing: _medianval5 ID: 174\n",
      "170928-15:51:48,884 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval5 jobid: 174\n",
      "170928-15:51:48,885 workflow INFO:\n",
      "\t Executing: _medianval6 ID: 175\n",
      "170928-15:51:48,888 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval6 jobid: 175\n",
      "170928-15:51:48,891 workflow INFO:\n",
      "\t Executing: _medianval7 ID: 176\n",
      "170928-15:51:48,892 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval7 jobid: 176\n",
      "170928-15:51:48,894 workflow INFO:\n",
      "\t Executing: _medianval8 ID: 177\n",
      "170928-15:51:48,895 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval8 jobid: 177\n",
      "170928-15:51:48,896 workflow INFO:\n",
      "\t Executing: _medianval9 ID: 178\n",
      "170928-15:51:48,898 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval9 jobid: 178\n",
      "170928-15:51:48,900 workflow INFO:\n",
      "\t Executing: _medianval10 ID: 179\n",
      "170928-15:51:48,902 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval10 jobid: 179\n",
      "170928-15:51:48,906 workflow INFO:\n",
      "\t Executing: _medianval11 ID: 180\n",
      "170928-15:51:48,907 workflow INFO:\n",
      "\t [Job finished] jobname: _medianval11 jobid: 180\n",
      "170928-15:51:48,909 workflow INFO:\n",
      "\t Executing: _maskfunc20 ID: 181\n",
      "170928-15:51:48,911 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc20 jobid: 181\n",
      "170928-15:51:48,912 workflow INFO:\n",
      "\t Executing: _maskfunc21 ID: 182\n",
      "170928-15:51:48,914 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc21 jobid: 182\n",
      "170928-15:51:48,915 workflow INFO:\n",
      "\t Executing: _maskfunc22 ID: 183\n",
      "170928-15:51:48,917 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc22 jobid: 183\n",
      "170928-15:51:48,921 workflow INFO:\n",
      "\t Executing: medianval ID: 10\n",
      "170928-15:51:48,923 workflow INFO:\n",
      "\t [Job finished] jobname: medianval jobid: 10\n",
      "170928-15:51:48,925 workflow INFO:\n",
      "\t Executing: _maskfunc23 ID: 184\n",
      "170928-15:51:48,926 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc23 jobid: 184\n",
      "170928-15:51:48,927 workflow INFO:\n",
      "\t Executing: _maskfunc24 ID: 185\n",
      "170928-15:51:48,928 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc24 jobid: 185\n",
      "170928-15:51:48,929 workflow INFO:\n",
      "\t Executing: _maskfunc25 ID: 186\n",
      "170928-15:51:48,930 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc25 jobid: 186\n",
      "170928-15:51:48,933 workflow INFO:\n",
      "\t Executing: _maskfunc26 ID: 187\n",
      "170928-15:51:48,934 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc26 jobid: 187\n",
      "170928-15:51:48,935 workflow INFO:\n",
      "\t Executing: _maskfunc27 ID: 188\n",
      "170928-15:51:48,937 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc27 jobid: 188\n",
      "170928-15:51:48,938 workflow INFO:\n",
      "\t Executing: _maskfunc28 ID: 189\n",
      "170928-15:51:48,939 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc28 jobid: 189\n",
      "170928-15:51:48,940 workflow INFO:\n",
      "\t Executing: _maskfunc29 ID: 190\n",
      "170928-15:51:48,941 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc29 jobid: 190\n",
      "170928-15:51:48,944 workflow INFO:\n",
      "\t Executing: _maskfunc210 ID: 191\n",
      "170928-15:51:48,946 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc210 jobid: 191\n",
      "170928-15:51:48,947 workflow INFO:\n",
      "\t Executing: _maskfunc211 ID: 192\n",
      "170928-15:51:48,948 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc211 jobid: 192\n",
      "170928-15:51:48,952 workflow INFO:\n",
      "\t Executing: maskfunc2 ID: 11\n",
      "170928-15:51:48,956 workflow INFO:\n",
      "\t [Job finished] jobname: maskfunc2 jobid: 11\n",
      "170928-15:51:48,960 workflow INFO:\n",
      "\t Executing: median ID: 12\n",
      "170928-15:51:48,974 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode median\n",
      "170928-15:51:48,979 workflow INFO:\n",
      "\t Executing: mask ID: 13\n",
      "170928-15:51:48,991 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode mask\n",
      "170928-15:51:49,0 workflow INFO:\n",
      "\t Executing: _median0 ID: 193\n",
      "170928-15:51:49,1 workflow INFO:\n",
      "\t [Job finished] jobname: _median0 jobid: 193\n",
      "170928-15:51:49,2 workflow INFO:\n",
      "\t Executing: _median1 ID: 194\n",
      "170928-15:51:49,3 workflow INFO:\n",
      "\t [Job finished] jobname: _median1 jobid: 194\n",
      "170928-15:51:49,4 workflow INFO:\n",
      "\t Executing: _median2 ID: 195\n",
      "170928-15:51:49,6 workflow INFO:\n",
      "\t [Job finished] jobname: _median2 jobid: 195\n",
      "170928-15:51:49,7 workflow INFO:\n",
      "\t Executing: _median3 ID: 196\n",
      "170928-15:51:49,8 workflow INFO:\n",
      "\t [Job finished] jobname: _median3 jobid: 196\n",
      "170928-15:51:49,12 workflow INFO:\n",
      "\t Executing: _median4 ID: 197\n",
      "170928-15:51:49,13 workflow INFO:\n",
      "\t [Job finished] jobname: _median4 jobid: 197\n",
      "170928-15:51:49,15 workflow INFO:\n",
      "\t Executing: _median5 ID: 198\n",
      "170928-15:51:49,17 workflow INFO:\n",
      "\t [Job finished] jobname: _median5 jobid: 198\n",
      "170928-15:51:49,18 workflow INFO:\n",
      "\t Executing: _median6 ID: 199\n",
      "170928-15:51:49,20 workflow INFO:\n",
      "\t [Job finished] jobname: _median6 jobid: 199\n",
      "170928-15:51:49,21 workflow INFO:\n",
      "\t Executing: _median7 ID: 200\n",
      "170928-15:51:49,23 workflow INFO:\n",
      "\t [Job finished] jobname: _median7 jobid: 200\n",
      "170928-15:51:49,26 workflow INFO:\n",
      "\t Executing: _median8 ID: 201\n",
      "170928-15:51:49,28 workflow INFO:\n",
      "\t [Job finished] jobname: _median8 jobid: 201\n",
      "170928-15:51:49,30 workflow INFO:\n",
      "\t Executing: _median9 ID: 202\n",
      "170928-15:51:49,32 workflow INFO:\n",
      "\t [Job finished] jobname: _median9 jobid: 202\n",
      "170928-15:51:49,33 workflow INFO:\n",
      "\t Executing: _median10 ID: 203\n",
      "170928-15:51:49,35 workflow INFO:\n",
      "\t [Job finished] jobname: _median10 jobid: 203\n",
      "170928-15:51:49,36 workflow INFO:\n",
      "\t Executing: _median11 ID: 204\n",
      "170928-15:51:49,37 workflow INFO:\n",
      "\t [Job finished] jobname: _median11 jobid: 204\n",
      "170928-15:51:49,41 workflow INFO:\n",
      "\t Executing: median ID: 12\n",
      "170928-15:51:49,46 workflow INFO:\n",
      "\t [Job finished] jobname: median jobid: 12\n",
      "170928-15:51:49,47 workflow INFO:\n",
      "\t Executing: _mask0 ID: 205\n",
      "170928-15:51:49,49 workflow INFO:\n",
      "\t [Job finished] jobname: _mask0 jobid: 205\n",
      "170928-15:51:49,50 workflow INFO:\n",
      "\t Executing: _mask1 ID: 206\n",
      "170928-15:51:49,51 workflow INFO:\n",
      "\t [Job finished] jobname: _mask1 jobid: 206\n",
      "170928-15:51:49,53 workflow INFO:\n",
      "\t Executing: _mask2 ID: 207\n",
      "170928-15:51:49,55 workflow INFO:\n",
      "\t [Job finished] jobname: _mask2 jobid: 207\n",
      "170928-15:51:49,58 workflow INFO:\n",
      "\t Executing: _mask3 ID: 208\n",
      "170928-15:51:49,60 workflow INFO:\n",
      "\t [Job finished] jobname: _mask3 jobid: 208\n",
      "170928-15:51:49,62 workflow INFO:\n",
      "\t Executing: _mask4 ID: 209\n",
      "170928-15:51:49,64 workflow INFO:\n",
      "\t [Job finished] jobname: _mask4 jobid: 209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170928-15:51:49,65 workflow INFO:\n",
      "\t Executing: _mask5 ID: 210\n",
      "170928-15:51:49,66 workflow INFO:\n",
      "\t [Job finished] jobname: _mask5 jobid: 210\n",
      "170928-15:51:49,67 workflow INFO:\n",
      "\t Executing: _mask6 ID: 211\n",
      "170928-15:51:49,68 workflow INFO:\n",
      "\t [Job finished] jobname: _mask6 jobid: 211\n",
      "170928-15:51:49,72 workflow INFO:\n",
      "\t Executing: _mask7 ID: 212\n",
      "170928-15:51:49,74 workflow INFO:\n",
      "\t [Job finished] jobname: _mask7 jobid: 212\n",
      "170928-15:51:49,75 workflow INFO:\n",
      "\t Executing: _mask8 ID: 213\n",
      "170928-15:51:49,76 workflow INFO:\n",
      "\t [Job finished] jobname: _mask8 jobid: 213\n",
      "170928-15:51:49,78 workflow INFO:\n",
      "\t Executing: _mask9 ID: 214\n",
      "170928-15:51:49,80 workflow INFO:\n",
      "\t [Job finished] jobname: _mask9 jobid: 214\n",
      "170928-15:51:49,82 workflow INFO:\n",
      "\t Executing: _mask10 ID: 215\n",
      "170928-15:51:49,83 workflow INFO:\n",
      "\t [Job finished] jobname: _mask10 jobid: 215\n",
      "170928-15:51:49,88 workflow INFO:\n",
      "\t Executing: _mask11 ID: 216\n",
      "170928-15:51:49,90 workflow INFO:\n",
      "\t [Job finished] jobname: _mask11 jobid: 216\n",
      "170928-15:51:49,93 workflow INFO:\n",
      "\t Executing: mask ID: 13\n",
      "170928-15:51:49,96 workflow INFO:\n",
      "\t [Job finished] jobname: mask jobid: 13\n",
      "170928-15:51:49,100 workflow INFO:\n",
      "\t Executing: meanfunc2 ID: 14\n",
      "170928-15:51:49,108 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode meanfunc2\n",
      "170928-15:51:49,115 workflow INFO:\n",
      "\t Executing: _meanfunc20 ID: 217\n",
      "170928-15:51:49,117 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc20 jobid: 217\n",
      "170928-15:51:49,118 workflow INFO:\n",
      "\t Executing: _meanfunc21 ID: 218\n",
      "170928-15:51:49,120 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc21 jobid: 218\n",
      "170928-15:51:49,121 workflow INFO:\n",
      "\t Executing: _meanfunc22 ID: 219\n",
      "170928-15:51:49,122 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc22 jobid: 219\n",
      "170928-15:51:49,123 workflow INFO:\n",
      "\t Executing: _meanfunc23 ID: 220\n",
      "170928-15:51:49,124 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc23 jobid: 220\n",
      "170928-15:51:49,128 workflow INFO:\n",
      "\t Executing: _meanfunc24 ID: 221\n",
      "170928-15:51:49,130 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc24 jobid: 221\n",
      "170928-15:51:49,132 workflow INFO:\n",
      "\t Executing: _meanfunc25 ID: 222\n",
      "170928-15:51:49,133 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc25 jobid: 222\n",
      "170928-15:51:49,134 workflow INFO:\n",
      "\t Executing: _meanfunc26 ID: 223\n",
      "170928-15:51:49,136 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc26 jobid: 223\n",
      "170928-15:51:49,137 workflow INFO:\n",
      "\t Executing: _meanfunc27 ID: 224\n",
      "170928-15:51:49,138 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc27 jobid: 224\n",
      "170928-15:51:49,141 workflow INFO:\n",
      "\t Executing: _meanfunc28 ID: 225\n",
      "170928-15:51:49,142 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc28 jobid: 225\n",
      "170928-15:51:49,143 workflow INFO:\n",
      "\t Executing: _meanfunc29 ID: 226\n",
      "170928-15:51:49,144 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc29 jobid: 226\n",
      "170928-15:51:49,145 workflow INFO:\n",
      "\t Executing: _meanfunc210 ID: 227\n",
      "170928-15:51:49,147 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc210 jobid: 227\n",
      "170928-15:51:49,148 workflow INFO:\n",
      "\t Executing: _meanfunc211 ID: 228\n",
      "170928-15:51:49,149 workflow INFO:\n",
      "\t [Job finished] jobname: _meanfunc211 jobid: 228\n",
      "170928-15:51:49,152 workflow INFO:\n",
      "\t Executing: meanfunc2 ID: 14\n",
      "170928-15:51:49,154 workflow INFO:\n",
      "\t [Job finished] jobname: meanfunc2 jobid: 14\n",
      "170928-15:51:49,158 workflow INFO:\n",
      "\t Executing: merge ID: 15\n",
      "170928-15:51:49,162 workflow INFO:\n",
      "\t [Job finished] jobname: merge jobid: 15\n",
      "170928-15:51:49,166 workflow INFO:\n",
      "\t Executing: smooth ID: 16\n",
      "170928-15:51:49,176 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode smooth\n",
      "170928-15:51:49,187 workflow INFO:\n",
      "\t Executing: _smooth0 ID: 229\n",
      "170928-15:51:49,189 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth0 jobid: 229\n",
      "170928-15:51:49,190 workflow INFO:\n",
      "\t Executing: _smooth1 ID: 230\n",
      "170928-15:51:49,191 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth1 jobid: 230\n",
      "170928-15:51:49,193 workflow INFO:\n",
      "\t Executing: _smooth2 ID: 231\n",
      "170928-15:51:49,195 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth2 jobid: 231\n",
      "170928-15:51:49,196 workflow INFO:\n",
      "\t Executing: _smooth3 ID: 232\n",
      "170928-15:51:49,198 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth3 jobid: 232\n",
      "170928-15:51:49,205 workflow INFO:\n",
      "\t Executing: _smooth4 ID: 233\n",
      "170928-15:51:49,208 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth4 jobid: 233\n",
      "170928-15:51:49,210 workflow INFO:\n",
      "\t Executing: _smooth5 ID: 234\n",
      "170928-15:51:49,212 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth5 jobid: 234\n",
      "170928-15:51:49,214 workflow INFO:\n",
      "\t Executing: _smooth6 ID: 235\n",
      "170928-15:51:49,216 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth6 jobid: 235\n",
      "170928-15:51:49,217 workflow INFO:\n",
      "\t Executing: _smooth7 ID: 236\n",
      "170928-15:51:49,219 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth7 jobid: 236\n",
      "170928-15:51:49,222 workflow INFO:\n",
      "\t Executing: _smooth8 ID: 237\n",
      "170928-15:51:49,224 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth8 jobid: 237\n",
      "170928-15:51:49,225 workflow INFO:\n",
      "\t Executing: _smooth9 ID: 238\n",
      "170928-15:51:49,227 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth9 jobid: 238\n",
      "170928-15:51:49,228 workflow INFO:\n",
      "\t Executing: _smooth10 ID: 239\n",
      "170928-15:51:49,231 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth10 jobid: 239\n",
      "170928-15:51:49,232 workflow INFO:\n",
      "\t Executing: _smooth11 ID: 240\n",
      "170928-15:51:49,234 workflow INFO:\n",
      "\t [Job finished] jobname: _smooth11 jobid: 240\n",
      "170928-15:51:49,237 workflow INFO:\n",
      "\t Executing: smooth ID: 16\n",
      "170928-15:51:49,239 workflow INFO:\n",
      "\t [Job finished] jobname: smooth jobid: 16\n",
      "170928-15:51:49,242 workflow INFO:\n",
      "\t Executing: maskfunc3 ID: 17\n",
      "170928-15:51:49,254 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode maskfunc3\n",
      "170928-15:51:49,263 workflow INFO:\n",
      "\t Executing: _maskfunc30 ID: 241\n",
      "170928-15:51:49,265 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc30 jobid: 241\n",
      "170928-15:51:49,266 workflow INFO:\n",
      "\t Executing: _maskfunc31 ID: 242\n",
      "170928-15:51:49,268 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc31 jobid: 242\n",
      "170928-15:51:49,270 workflow INFO:\n",
      "\t Executing: _maskfunc32 ID: 243\n",
      "170928-15:51:49,272 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc32 jobid: 243\n",
      "170928-15:51:49,273 workflow INFO:\n",
      "\t Executing: _maskfunc33 ID: 244\n",
      "170928-15:51:49,274 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc33 jobid: 244\n",
      "170928-15:51:49,279 workflow INFO:\n",
      "\t Executing: _maskfunc34 ID: 245\n",
      "170928-15:51:49,281 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc34 jobid: 245\n",
      "170928-15:51:49,283 workflow INFO:\n",
      "\t Executing: _maskfunc35 ID: 246\n",
      "170928-15:51:49,285 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc35 jobid: 246\n",
      "170928-15:51:49,286 workflow INFO:\n",
      "\t Executing: _maskfunc36 ID: 247\n",
      "170928-15:51:49,288 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc36 jobid: 247\n",
      "170928-15:51:49,288 workflow INFO:\n",
      "\t Executing: _maskfunc37 ID: 248\n",
      "170928-15:51:49,290 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc37 jobid: 248\n",
      "170928-15:51:49,295 workflow INFO:\n",
      "\t Executing: _maskfunc38 ID: 249\n",
      "170928-15:51:49,297 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc38 jobid: 249\n",
      "170928-15:51:49,298 workflow INFO:\n",
      "\t Executing: _maskfunc39 ID: 250\n",
      "170928-15:51:49,300 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc39 jobid: 250\n",
      "170928-15:51:49,301 workflow INFO:\n",
      "\t Executing: _maskfunc310 ID: 251\n",
      "170928-15:51:49,302 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc310 jobid: 251\n",
      "170928-15:51:49,304 workflow INFO:\n",
      "\t Executing: _maskfunc311 ID: 252\n",
      "170928-15:51:49,305 workflow INFO:\n",
      "\t [Job finished] jobname: _maskfunc311 jobid: 252\n",
      "170928-15:51:49,309 workflow INFO:\n",
      "\t Executing: maskfunc3 ID: 17\n",
      "170928-15:51:49,313 workflow INFO:\n",
      "\t [Job finished] jobname: maskfunc3 jobid: 17\n",
      "170928-15:51:49,318 workflow INFO:\n",
      "\t Executing: concat ID: 18\n",
      "170928-15:51:49,325 workflow INFO:\n",
      "\t [Job finished] jobname: concat jobid: 18\n",
      "170928-15:51:49,331 workflow INFO:\n",
      "\t Executing: select ID: 19\n",
      "170928-15:51:49,334 workflow INFO:\n",
      "\t [Job finished] jobname: select jobid: 19\n",
      "170928-15:51:49,340 workflow INFO:\n",
      "\t Executing: meanscale ID: 20\n",
      "170928-15:51:49,356 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode meanscale\n",
      "170928-15:51:49,368 workflow INFO:\n",
      "\t Executing: _meanscale0 ID: 253\n",
      "170928-15:51:49,369 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale0 jobid: 253\n",
      "170928-15:51:49,371 workflow INFO:\n",
      "\t Executing: _meanscale1 ID: 254\n",
      "170928-15:51:49,372 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale1 jobid: 254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170928-15:51:49,373 workflow INFO:\n",
      "\t Executing: _meanscale2 ID: 255\n",
      "170928-15:51:49,375 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale2 jobid: 255\n",
      "170928-15:51:49,376 workflow INFO:\n",
      "\t Executing: _meanscale3 ID: 256\n",
      "170928-15:51:49,378 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale3 jobid: 256\n",
      "170928-15:51:49,383 workflow INFO:\n",
      "\t Executing: _meanscale4 ID: 257\n",
      "170928-15:51:49,385 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale4 jobid: 257\n",
      "170928-15:51:49,386 workflow INFO:\n",
      "\t Executing: _meanscale5 ID: 258\n",
      "170928-15:51:49,388 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale5 jobid: 258\n",
      "170928-15:51:49,390 workflow INFO:\n",
      "\t Executing: _meanscale6 ID: 259\n",
      "170928-15:51:49,392 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale6 jobid: 259\n",
      "170928-15:51:49,394 workflow INFO:\n",
      "\t Executing: _meanscale7 ID: 260\n",
      "170928-15:51:49,396 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale7 jobid: 260\n",
      "170928-15:51:49,402 workflow INFO:\n",
      "\t Executing: _meanscale8 ID: 261\n",
      "170928-15:51:49,403 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale8 jobid: 261\n",
      "170928-15:51:49,404 workflow INFO:\n",
      "\t Executing: _meanscale9 ID: 262\n",
      "170928-15:51:49,406 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale9 jobid: 262\n",
      "170928-15:51:49,407 workflow INFO:\n",
      "\t Executing: _meanscale10 ID: 263\n",
      "170928-15:51:49,409 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale10 jobid: 263\n",
      "170928-15:51:49,410 workflow INFO:\n",
      "\t Executing: _meanscale11 ID: 264\n",
      "170928-15:51:49,411 workflow INFO:\n",
      "\t [Job finished] jobname: _meanscale11 jobid: 264\n",
      "170928-15:51:49,416 workflow INFO:\n",
      "\t Executing: meanscale ID: 20\n",
      "170928-15:51:49,419 workflow INFO:\n",
      "\t [Job finished] jobname: meanscale jobid: 20\n",
      "170928-15:51:49,424 workflow INFO:\n",
      "\t Executing: highpass ID: 21\n",
      "170928-15:51:49,432 workflow INFO:\n",
      "\t Adding 12 jobs for mapnode highpass\n",
      "170928-15:51:49,440 workflow INFO:\n",
      "\t Executing: _highpass0 ID: 265\n",
      "170928-15:51:49,441 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass0 jobid: 265\n",
      "170928-15:51:49,443 workflow INFO:\n",
      "\t Executing: _highpass1 ID: 266\n",
      "170928-15:51:49,445 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass1 jobid: 266\n",
      "170928-15:51:49,446 workflow INFO:\n",
      "\t Executing: _highpass2 ID: 267\n",
      "170928-15:51:49,448 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass2 jobid: 267\n",
      "170928-15:51:49,449 workflow INFO:\n",
      "\t Executing: _highpass3 ID: 268\n",
      "170928-15:51:49,451 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass3 jobid: 268\n",
      "170928-15:51:49,456 workflow INFO:\n",
      "\t Executing: _highpass4 ID: 269\n",
      "170928-15:51:49,458 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass4 jobid: 269\n",
      "170928-15:51:49,459 workflow INFO:\n",
      "\t Executing: _highpass5 ID: 270\n",
      "170928-15:51:49,461 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass5 jobid: 270\n",
      "170928-15:51:49,463 workflow INFO:\n",
      "\t Executing: _highpass6 ID: 271\n",
      "170928-15:51:49,464 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass6 jobid: 271\n",
      "170928-15:51:49,466 workflow INFO:\n",
      "\t Executing: _highpass7 ID: 272\n",
      "170928-15:51:49,467 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass7 jobid: 272\n",
      "170928-15:51:49,471 workflow INFO:\n",
      "\t Executing: _highpass8 ID: 273\n",
      "170928-15:51:49,473 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass8 jobid: 273\n",
      "170928-15:51:49,474 workflow INFO:\n",
      "\t Executing: _highpass9 ID: 274\n",
      "170928-15:51:49,475 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass9 jobid: 274\n",
      "170928-15:51:49,476 workflow INFO:\n",
      "\t Executing: _highpass10 ID: 275\n",
      "170928-15:51:49,478 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass10 jobid: 275\n",
      "170928-15:51:49,479 workflow INFO:\n",
      "\t Executing: _highpass11 ID: 276\n",
      "170928-15:51:49,481 workflow INFO:\n",
      "\t [Job finished] jobname: _highpass11 jobid: 276\n",
      "170928-15:51:49,486 workflow INFO:\n",
      "\t Executing: highpass ID: 21\n",
      "170928-15:51:49,489 workflow INFO:\n",
      "\t [Job finished] jobname: highpass jobid: 21\n",
      "170928-15:51:49,493 workflow INFO:\n",
      "\t Executing: datasink ID: 22\n",
      "170928-15:51:49,502 workflow INFO:\n",
      "\t Executing node datasink in dir: /home/deepak/Desktop/FConnectivityAnalysis/tmp/featpreproc/datasink\n",
      "170928-15:51:49,517 workflow INFO:\n",
      "\t [Job finished] jobname: datasink jobid: 22\n",
      "\n",
      "Total time taken for running the program:  2.5659241050016135\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import Preprocess_network as parallelPreproc\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "# JSONFile = sys.argv[1]\n",
    "JSONFile = '/home/deepak/Desktop/FConnectivityAnalysis/FConnectivityAnalysisDesign.json'\n",
    "with open(JSONFile) as JSON:\n",
    "    try :\n",
    "        \n",
    "        data = json.load(JSON)\n",
    "        AnalysisName = data['Analysis Name']\n",
    "    #     print(AnalysisName)\n",
    "        WorkingDir = data['WorkingDir']\n",
    "        AnalysisParams = data['AnalysisParams']\n",
    "        \n",
    "    except :\n",
    "        print('Unexpected error:', sys.exc_info()[0])\n",
    "        raise\n",
    "def run_Preprocessing(AnalysisParams,FunctionalFiles,StructuralFiles):\n",
    "    B0unwarping = AnalysisParams['B0 Unwarping']\n",
    "    BETextract = AnalysisParams['BET Brain Extract']\n",
    "    FWHM = AnalysisParams['FWHM']\n",
    "    HighPass = AnalysisParams['High Pass']\n",
    "    MotionCorrection = AnalysisParams['Motion Correction']\n",
    "    Registration = AnalysisParams['Registration']\n",
    "    SliceTimeCorrect = AnalysisParams['Slice Time Correct']\n",
    "    Intensity_Norm = AnalysisParams['Intensity Normalization']\n",
    "    MelodicICA = AnalysisParams['Melodic ICA']\n",
    "    PerfusionSubtract = AnalysisParams['Perfusion Subtraction']\n",
    "    OUTPUT_DIR = AnalysisParams['OutputInfo']['OutDirectory']\n",
    "    RESULTS_DATASINK = OUTPUT_DIR + \"/tmp/featpreproc/datasink/\"\n",
    "      \n",
    "        \n",
    "    if HighPass:\n",
    "        preproc = parallelPreproc.create_parallelfeat_preproc(highpass= HighPass, \n",
    "                                    Intensity_Norm = Intensity_Norm,\n",
    "                                    BETextract = BETextract,\n",
    "                                    MotionCorrection = MotionCorrection, \n",
    "                                    SliceTimeCorrect = SliceTimeCorrect)\n",
    "        preproc.inputs.inputspec.highpass = 128./(2*2.5)\n",
    "        preproc.inputs.inputspec.func = FunctionalFiles\n",
    "        preproc.inputs.inputspec.fwhm = FWHM\n",
    "        preproc.base_dir = OUTPUT_DIR + '/tmp'\n",
    "        preproc.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "        preproc.run('MultiProc', plugin_args={'n_procs': 4})\n",
    "        \n",
    "    else:\n",
    "        preproc = parallelPreproc.create_parallelfeat_preproc(highpass= HighPass, \n",
    "                                    Intensity_Norm = Intensity_Norm,\n",
    "                                    BETextract = BETextract,\n",
    "                                    MotionCorrection = MotionCorrection, \n",
    "                                    SliceTimeCorrect = SliceTimeCorrect)\n",
    "        preproc.inputs.inputspec.func = FunctionalFiles\n",
    "        preproc.inputs.inputspec.fwhm = FWHM\n",
    "        preproc.base_dir = OUTPUT_DIR + '/tmp'\n",
    "        preproc.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "        preproc.run('MultiProc', plugin_args={'n_procs': 4})\n",
    "    \n",
    "    datasink_results=[]\n",
    "    datasink_results += [each for each in os.listdir(RESULTS_DATASINK) if each.endswith('.json')]\n",
    "    with open(RESULTS_DATASINK + datasink_results[0]) as JSON:\n",
    "        datafile = json.load(JSON)\n",
    "        datafile =datafile[0][1][0][1]\n",
    "    datasinkouts = []\n",
    "    datasinkouts += [datafile[i][0] for i in range(len(datafile))]\n",
    "    \n",
    "    \n",
    "    return datasinkouts\n",
    "\n",
    "\n",
    "ReferenceFile = AnalysisParams['ReferSummary']['ReferImgPath']\n",
    "ProcessingWay = AnalysisParams['ProcessingType']['ProcessingWay']\n",
    "Ngroups = AnalysisParams['No of Groups']\n",
    "if (ProcessingWay==0):\n",
    "    FunctionaltxtFiles = AnalysisParams['FilesInfo']['FunctionalFilePaths']\n",
    "    StructuraltxtFiles = AnalysisParams['FilesInfo']['StructuralFilePaths']\n",
    "\n",
    "    for i in range(0,Ngroups):\n",
    "        with open(FunctionaltxtFiles[i]) as file:\n",
    "            FunctionalFiles_in_this_group = [line.strip('\\n') for line in file]\n",
    "        with open(StructuraltxtFiles[i]) as file:\n",
    "            StructuralFiles_in_this_group = [line.strip('\\n') for line in file]\n",
    "        Preprocessed_Files = run_Preprocessing(AnalysisParams, FunctionalFiles_in_this_group, StructuralFiles_in_this_group)\n",
    "        print(Preprocessed_Files)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(\"Total time taken for running the program: \", stop - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Graph.size of <networkx.classes.digraph.DiGraph object at 0x7f7e8e16feb8>>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nipype.interfaces.utility as util\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "\n",
    "from nipype.interfaces import fsl\n",
    "import nipype.workflows.fmri.fsl.preprocess as Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_WorkFlow = Preprocessor.create_reg_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageMaths' object has no attribute 'out_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-bd748b30b269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Reg_WorkFlow.connect(meanfunc, 'out_file', Reg_WorkFlow.inputs.inputspec, 'mean_image')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mReg_WorkFlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeanfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageMaths' object has no attribute 'out_file'"
     ]
    }
   ],
   "source": [
    "meanfunc = fsl.ImageMaths(op_string='-Tmean',\n",
    "                                                    suffix='_mean', \n",
    "            in_file = '/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3577037/session_1/rest_1/rest_linearMNI3mm.nii.gz')\n",
    "    \n",
    "\n",
    "#Reg_WorkFlow.connect(meanfunc, 'out_file', Reg_WorkFlow.inputs.inputspec, 'mean_image')\n",
    "Reg_WorkFlow.inputs.inputspec.mean_image = meanfunc.out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deepak/Desktop/funcConn/funcConnGUI/Scripts/foo_maths.nii.gz'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_workflow(name = 'registration'):\n",
    "    \"\"\"Create a FEAT preprocessing workflow\n",
    "    Parameters\n",
    "    ----------\n",
    "    ::\n",
    "        name : name of workflow (default: 'registration')\n",
    "    Inputs::\n",
    "        inputspec.source_files : files (filename or list of filenames to register)\n",
    "        inputspec.mean_image : reference image to use\n",
    "        inputspec.anatomical_image : anatomical image to coregister to\n",
    "        inputspec.target_image : registration target\n",
    "    Outputs::\n",
    "        outputspec.func2anat_transform : FLIRT transform\n",
    "        outputspec.anat2target_transform : FLIRT+FNIRT transform\n",
    "        outputspec.transformed_files : transformed files in target space\n",
    "        outputspec.transformed_mean : mean image in target space\n",
    "    Example\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "    register = Workflow(name=name)\n",
    "\n",
    "    inputnode = Node(interface=util.IdentityInterface(fields=['source_files',\n",
    "                                                                 'anatomical_image',\n",
    "                                                                 'target_image']),\n",
    "                        name='inputspec')\n",
    "    outputnode = Node(interface=util.IdentityInterface(fields=['func2anat_transform',\n",
    "                                                                  'anat2target_transform',\n",
    "                                                                  'transformed_files',\n",
    "                                                                  'transformed_mean',\n",
    "                                                                  ]),\n",
    "                         name='outputspec')\n",
    "    meanfunc = Node(fsl.ImageMaths(op_string='-Tmean',suffix='_mean'), name = 'meanfunc')\n",
    "    register.connect(inputnode, 'source_files', meanfunc, 'in_file')\n",
    "    \"\"\"\n",
    "    Estimate the tissue classes from the anatomical image. But use spm's segment\n",
    "    as FSL appears to be breaking.\n",
    "    \"\"\"\n",
    "\n",
    "    stripper = Node(fsl.BET(), name='stripper')\n",
    "    register.connect(inputnode, 'anatomical_image', stripper, 'in_file')\n",
    "    fast = Node(fsl.FAST(), name='fast')\n",
    "    register.connect(stripper, 'out_file', fast, 'in_files')\n",
    "\n",
    "    \"\"\"\n",
    "    Binarize the segmentation\n",
    "    \"\"\"\n",
    "\n",
    "    binarize = Node(fsl.ImageMaths(op_string='-nan -thr 0.5 -bin'),\n",
    "                       name='binarize')\n",
    "    pickindex = lambda x, i: x[i]\n",
    "    register.connect(fast, ('partial_volume_files', pickindex, 2),\n",
    "                     binarize, 'in_file')\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate rigid transform from mean image to anatomical image\n",
    "    \"\"\"\n",
    "\n",
    "    mean2anat = Node(fsl.FLIRT(), name='mean2anat')\n",
    "    mean2anat.inputs.dof = 6\n",
    "    register.connect(meanfunc,'out_file', mean2anat, 'in_file')\n",
    "    register.connect(stripper, 'out_file', mean2anat, 'reference')\n",
    "\n",
    "    \"\"\"\n",
    "    Now use bbr cost function to improve the transform\n",
    "    \"\"\"\n",
    "\n",
    "    mean2anatbbr = Node(fsl.FLIRT(), name='mean2anatbbr')\n",
    "    mean2anatbbr.inputs.dof = 6\n",
    "    mean2anatbbr.inputs.cost = 'bbr'\n",
    "    mean2anatbbr.inputs.schedule = os.path.join(os.getenv('FSLDIR'),\n",
    "                                                'etc/flirtsch/bbr.sch')\n",
    "    register.connect(meanfunc,'out_file', mean2anatbbr, 'in_file')\n",
    "    register.connect(binarize, 'out_file', mean2anatbbr, 'wm_seg')\n",
    "    register.connect(inputnode, 'anatomical_image', mean2anatbbr, 'reference')\n",
    "    register.connect(mean2anat, 'out_matrix_file',\n",
    "                     mean2anatbbr, 'in_matrix_file')\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate affine transform from anatomical to target\n",
    "    \"\"\"\n",
    "\n",
    "    anat2target_affine = Node(fsl.FLIRT(), name='anat2target_linear')\n",
    "    anat2target_affine.inputs.searchr_x = [-180, 180]\n",
    "    anat2target_affine.inputs.searchr_y = [-180, 180]\n",
    "    anat2target_affine.inputs.searchr_z = [-180, 180]\n",
    "    register.connect(stripper, 'out_file', anat2target_affine, 'in_file')\n",
    "    register.connect(inputnode, 'target_image',\n",
    "                     anat2target_affine, 'reference')\n",
    "\n",
    "\n",
    "#     register.connect(anat2target_affine, 'out_matrix_file',\n",
    "#                      anat2target_nonlinear, 'affine_file')\n",
    "#     register.connect(inputnode, 'anatomical_image',\n",
    "#                      anat2target_nonlinear, 'in_file')\n",
    "#     register.connect(inputnode, 'config_file',\n",
    "#                      anat2target_nonlinear, 'config_file')\n",
    "#     register.connect(inputnode, 'target_image',\n",
    "#                      anat2target_nonlinear, 'ref_file')\n",
    "\n",
    "    \"\"\"\n",
    "    Transform the mean image. First to anatomical and then to target\n",
    "    \"\"\"\n",
    "\n",
    "    warpmean = Node(fsl.ApplyWarp(interp='spline'), name='warpmean')\n",
    "    register.connect(meanfunc,'out_file', warpmean, 'in_file')\n",
    "    register.connect(mean2anatbbr, 'out_matrix_file', warpmean, 'premat')\n",
    "    register.connect(inputnode, 'target_image', warpmean, 'ref_file')\n",
    "#     register.connect(anat2target_nonlinear, 'fieldcoeff_file',\n",
    "#                      warpmean, 'field_file')\n",
    "    register.connect(anat2target_affine, 'out_matrix_file',\n",
    "                     warpmean, 'postmat')\n",
    "    \n",
    "    \"\"\"\n",
    "    Transform the remaining images. First to anatomical and then to target\n",
    "    \"\"\"\n",
    "\n",
    "    warpall = MapNode(fsl.ApplyWarp(interp='spline'),\n",
    "                         iterfield=['in_file'],\n",
    "                         nested=True,\n",
    "                         name='warpall')\n",
    "    datasink = Node(interface=DataSink(), name=\"datasink\")\n",
    "    register.connect(inputnode, 'source_files', warpall, 'in_file')\n",
    "    register.connect(mean2anatbbr, 'out_matrix_file', warpall, 'premat')\n",
    "    register.connect(inputnode, 'target_image', warpall, 'ref_file')\n",
    "#     register.connect(anat2target_nonlinear, 'fieldcoeff_file',\n",
    "#                      warpall, 'field_file')\n",
    "    register.connect(anat2target_affine, 'out_matrix_file',\n",
    "                     warpall, 'postmat')\n",
    "\n",
    "    \"\"\"\n",
    "    Assign all the output files\n",
    "    \"\"\"\n",
    "\n",
    "    register.connect(warpmean, 'out_file', outputnode, 'transformed_mean')\n",
    "    register.connect(warpall, 'out_file', outputnode, 'transformed_files')\n",
    "    register.connect(mean2anatbbr, 'out_matrix_file',\n",
    "                     outputnode, 'func2anat_transform')\n",
    "#     register.connect(anat2target_nonlinear, 'fieldcoeff_file',\n",
    "#                      outputnode, 'anat2target_transform')\n",
    "    register.connect(anat2target_affine, 'out_matrix_file',\n",
    "                     outputnode, 'anat2target_transform')\n",
    "    register.connect(warpall, 'out_file', datasink,'out_file') \n",
    "\n",
    "    \n",
    "    return register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170928-19:10:21,689 workflow INFO:\n",
      "\t Workflow registration settings: ['check', 'execution', 'logging']\n",
      "170928-19:10:21,696 workflow INFO:\n",
      "\t Running serially.\n",
      "170928-19:10:21,697 workflow INFO:\n",
      "\t Executing node stripper in dir: /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/stripper\n",
      "170928-19:10:21,698 workflow INFO:\n",
      "\t Collecting precomputed outputs\n",
      "170928-19:10:21,699 workflow INFO:\n",
      "\t Executing node fast in dir: /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/fast\n",
      "170928-19:10:21,700 workflow INFO:\n",
      "\t Collecting precomputed outputs\n",
      "170928-19:10:21,703 workflow INFO:\n",
      "\t Executing node binarize in dir: /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/binarize\n",
      "170928-19:10:21,704 workflow INFO:\n",
      "\t Collecting precomputed outputs\n",
      "170928-19:10:21,705 workflow INFO:\n",
      "\t Executing node anat2target_linear in dir: /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/anat2target_linear\n",
      "170928-19:10:21,706 workflow INFO:\n",
      "\t Collecting precomputed outputs\n",
      "170928-19:10:21,707 workflow INFO:\n",
      "\t Executing node meanfunc in dir: /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/meanfunc\n",
      "170928-19:10:21,711 workflow INFO:\n",
      "\t Running: fslmaths /home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/1065809/session_1/rest_1/rest_linearMNI3mm.nii.gz -Tmean /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/meanfunc/rest_linearMNI3mm_mean.nii.gz\n",
      "170928-19:10:24,283 workflow INFO:\n",
      "\t Executing node mean2anat in dir: /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/mean2anat\n",
      "170928-19:10:24,289 workflow INFO:\n",
      "\t Running: flirt -in /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/meanfunc/rest_linearMNI3mm_mean.nii.gz -ref /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/stripper/MNI152_T1_2mm_brain_brain.nii.gz -out rest_linearMNI3mm_mean_flirt.nii.gz -omat rest_linearMNI3mm_mean_flirt.mat -dof 6\n",
      "170928-19:10:26,866 workflow INFO:\n",
      "\t Executing node mean2anatbbr in dir: /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/mean2anatbbr\n",
      "170928-19:10:26,871 workflow INFO:\n",
      "\t Running: flirt -in /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/meanfunc/rest_linearMNI3mm_mean.nii.gz -ref /usr/share/fsl/5.0/data/standard/MNI152_T1_2mm_brain.nii.gz -out rest_linearMNI3mm_mean_flirt.nii.gz -omat rest_linearMNI3mm_mean_flirt.mat -cost bbr -dof 6 -init /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/mean2anat/rest_linearMNI3mm_mean_flirt.mat -schedule /usr/share/fsl/5.0/etc/flirtsch/bbr.sch -wmseg /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/binarize/MNI152_T1_2mm_brain_brain_pve_2_maths.nii.gz\n",
      "170928-19:10:50,889 interface INFO:\n",
      "\t stdout 2017-09-28T19:10:50.889129:0.773072 0.999894 -0.014541 0.000654 0.000000 0.014538 0.999884 0.004558 0.000000 -0.000720 -0.004548 0.999989 0.000000 -1.780939 1.657887 3.821979 1.000000 \n",
      "170928-19:10:51,402 workflow INFO:\n",
      "\t Executing node warpall in dir: /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/warpall\n",
      "170928-19:10:51,408 workflow INFO:\n",
      "\t Executing node _warpall0 in dir: /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/warpall/mapflow/_warpall0\n",
      "170928-19:10:51,414 workflow INFO:\n",
      "\t Running: applywarp --in=/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/1065809/session_1/rest_1/rest_linearMNI3mm.nii.gz --ref=/usr/share/fsl/5.0/data/standard/MNI152_T1_2mm_brain.nii.gz --out=/home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/warpall/mapflow/_warpall0/rest_linearMNI3mm_warp.nii.gz --postmat=/home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/anat2target_linear/MNI152_T1_2mm_brain_brain_flirt.mat --premat=/home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/mean2anatbbr/rest_linearMNI3mm_mean_flirt.mat --interp=spline\n",
      "170928-19:12:43,768 workflow INFO:\n",
      "\t Executing node datasink in dir: /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/datasink\n",
      "170928-19:12:43,816 workflow INFO:\n",
      "\t Executing node warpmean in dir: /home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/warpmean\n",
      "170928-19:12:43,822 workflow INFO:\n",
      "\t Running: applywarp --in=/home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/meanfunc/rest_linearMNI3mm_mean.nii.gz --ref=/usr/share/fsl/5.0/data/standard/MNI152_T1_2mm_brain.nii.gz --out=/home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/warpmean/rest_linearMNI3mm_mean_warp.nii.gz --postmat=/home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/anat2target_linear/MNI152_T1_2mm_brain_brain_flirt.mat --premat=/home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/mean2anatbbr/rest_linearMNI3mm_mean_flirt.mat --interp=spline\n"
     ]
    }
   ],
   "source": [
    "Reg_WorkFlow = reg_workflow()\n",
    "Reg_WorkFlow.inputs.inputspec.source_files = '/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/1065809/session_1/rest_1/rest_linearMNI3mm.nii.gz'\n",
    "\n",
    "Reg_WorkFlow.inputs.inputspec.anatomical_image = '/usr/share/fsl/5.0/data/standard/MNI152_T1_2mm_brain.nii.gz'\n",
    "Reg_WorkFlow.inputs.inputspec.target_image = '/usr/share/fsl/5.0/data/standard/MNI152_T1_2mm_brain.nii.gz'\n",
    "\n",
    "Reg_WorkFlow.base_dir = os.getcwd() + '/tmp'\n",
    "\n",
    "\n",
    "regoutputs = Reg_WorkFlow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_REG_DATASINK = '/home/deepak/Desktop/funcConn/funcConnGUI/Scripts/tmp/registration/datasink/'\n",
    "datasink_results=[]\n",
    "datasink_results += [each for each in os.listdir(RESULTS_REG_DATASINK) if each.endswith('.json')]\n",
    "with open(RESULTS_REG_DATASINK + datasink_results[0]) as JSON:\n",
    "    datafile = json.load(JSON)\n",
    "    datafile =datafile[0][1][0][1]\n",
    "datasinkouts = []\n",
    "datasinkouts += [datafile[i][0] for i in range(len(datafile))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps command **flirt**\n",
      "\n",
      "Use FSL FLIRT for coregistration.\n",
      "\n",
      "For complete details, see the `FLIRT Documentation.\n",
      "<https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT>`_\n",
      "\n",
      "To print out the command line help, use:\n",
      "    fsl.FLIRT().inputs_help()\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from nipype.interfaces import fsl\n",
      ">>> from nipype.testing import example_data\n",
      ">>> flt = fsl.FLIRT(bins=640, cost_func='mutualinfo')\n",
      ">>> flt.inputs.in_file = 'structural.nii'\n",
      ">>> flt.inputs.reference = 'mni.nii'\n",
      ">>> flt.inputs.output_type = \"NIFTI_GZ\"\n",
      ">>> flt.cmdline # doctest: +ELLIPSIS +ALLOW_UNICODE\n",
      "'flirt -in structural.nii -ref mni.nii -out structural_flirt.nii.gz -omat structural_flirt.mat -bins 640 -searchcost mutualinfo'\n",
      ">>> res = flt.run() #doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tin_file: (an existing file name)\n",
      "\t\tinput file\n",
      "\t\tflag: -in %s, position: 0\n",
      "\treference: (an existing file name)\n",
      "\t\treference file\n",
      "\t\tflag: -ref %s, position: 1\n",
      "\n",
      "\t[Optional]\n",
      "\tangle_rep: ('quaternion' or 'euler')\n",
      "\t\trepresentation of rotation angles\n",
      "\t\tflag: -anglerep %s\n",
      "\tapply_isoxfm: (a float)\n",
      "\t\tas applyxfm but forces isotropic resampling\n",
      "\t\tflag: -applyisoxfm %f\n",
      "\t\tmutually_exclusive: apply_xfm\n",
      "\tapply_xfm: (a boolean)\n",
      "\t\tapply transformation supplied by in_matrix_file or uses_qform to use\n",
      "\t\tthe affine matrix stored in the reference header\n",
      "\t\tflag: -applyxfm\n",
      "\targs: (a unicode string)\n",
      "\t\tAdditional parameters to the command\n",
      "\t\tflag: %s\n",
      "\tbbrslope: (a float)\n",
      "\t\tvalue of bbr slope\n",
      "\t\tflag: -bbrslope %f\n",
      "\tbbrtype: ('signed' or 'global_abs' or 'local_abs')\n",
      "\t\ttype of bbr cost function: signed [default], global_abs, local_abs\n",
      "\t\tflag: -bbrtype %s\n",
      "\tbgvalue: (a float)\n",
      "\t\tuse specified background value for points outside FOV\n",
      "\t\tflag: -setbackground %f\n",
      "\tbins: (an integer (int or long))\n",
      "\t\tnumber of histogram bins\n",
      "\t\tflag: -bins %d\n",
      "\tcoarse_search: (an integer (int or long))\n",
      "\t\tcoarse search delta angle\n",
      "\t\tflag: -coarsesearch %d\n",
      "\tcost: ('mutualinfo' or 'corratio' or 'normcorr' or 'normmi' or\n",
      "\t\t 'leastsq' or 'labeldiff' or 'bbr')\n",
      "\t\tcost function\n",
      "\t\tflag: -cost %s\n",
      "\tcost_func: ('mutualinfo' or 'corratio' or 'normcorr' or 'normmi' or\n",
      "\t\t 'leastsq' or 'labeldiff' or 'bbr')\n",
      "\t\tcost function\n",
      "\t\tflag: -searchcost %s\n",
      "\tdatatype: ('char' or 'short' or 'int' or 'float' or 'double')\n",
      "\t\tforce output data type\n",
      "\t\tflag: -datatype %s\n",
      "\tdisplay_init: (a boolean)\n",
      "\t\tdisplay initial matrix\n",
      "\t\tflag: -displayinit\n",
      "\tdof: (an integer (int or long))\n",
      "\t\tnumber of transform degrees of freedom\n",
      "\t\tflag: -dof %d\n",
      "\techospacing: (a float)\n",
      "\t\tvalue of EPI echo spacing - units of seconds\n",
      "\t\tflag: -echospacing %f\n",
      "\tenviron: (a dictionary with keys which are a bytes or None or a value\n",
      "\t\t of class 'str' and with values which are a bytes or None or a value\n",
      "\t\t of class 'str', nipype default value: {})\n",
      "\t\tEnvironment variables\n",
      "\tfieldmap: (a file name)\n",
      "\t\tfieldmap image in rads/s - must be already registered to the\n",
      "\t\treference image\n",
      "\t\tflag: -fieldmap %s\n",
      "\tfieldmapmask: (a file name)\n",
      "\t\tmask for fieldmap image\n",
      "\t\tflag: -fieldmapmask %s\n",
      "\tfine_search: (an integer (int or long))\n",
      "\t\tfine search delta angle\n",
      "\t\tflag: -finesearch %d\n",
      "\tforce_scaling: (a boolean)\n",
      "\t\tforce rescaling even for low-res images\n",
      "\t\tflag: -forcescaling\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tin_matrix_file: (a file name)\n",
      "\t\tinput 4x4 affine matrix\n",
      "\t\tflag: -init %s\n",
      "\tin_weight: (an existing file name)\n",
      "\t\tFile for input weighting volume\n",
      "\t\tflag: -inweight %s\n",
      "\tinterp: ('trilinear' or 'nearestneighbour' or 'sinc' or 'spline')\n",
      "\t\tfinal interpolation method used in reslicing\n",
      "\t\tflag: -interp %s\n",
      "\tmin_sampling: (a float)\n",
      "\t\tset minimum voxel dimension for sampling\n",
      "\t\tflag: -minsampling %f\n",
      "\tno_clamp: (a boolean)\n",
      "\t\tdo not use intensity clamping\n",
      "\t\tflag: -noclamp\n",
      "\tno_resample: (a boolean)\n",
      "\t\tdo not change input sampling\n",
      "\t\tflag: -noresample\n",
      "\tno_resample_blur: (a boolean)\n",
      "\t\tdo not use blurring on downsampling\n",
      "\t\tflag: -noresampblur\n",
      "\tno_search: (a boolean)\n",
      "\t\tset all angular searches to ranges 0 to 0\n",
      "\t\tflag: -nosearch\n",
      "\tout_file: (a file name)\n",
      "\t\tregistered output file\n",
      "\t\tflag: -out %s, position: 2\n",
      "\tout_log: (a file name)\n",
      "\t\toutput log\n",
      "\t\trequires: save_log\n",
      "\tout_matrix_file: (a file name)\n",
      "\t\toutput affine matrix in 4x4 asciii format\n",
      "\t\tflag: -omat %s, position: 3\n",
      "\toutput_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "\t\t 'NIFTI_PAIR_GZ')\n",
      "\t\tFSL output type\n",
      "\tpadding_size: (an integer (int or long))\n",
      "\t\tfor applyxfm: interpolates outside image by size\n",
      "\t\tflag: -paddingsize %d\n",
      "\tpedir: (an integer (int or long))\n",
      "\t\tphase encode direction of EPI - 1/2/3=x/y/z & -1/-2/-3=-x/-y/-z\n",
      "\t\tflag: -pedir %d\n",
      "\tref_weight: (an existing file name)\n",
      "\t\tFile for reference weighting volume\n",
      "\t\tflag: -refweight %s\n",
      "\trigid2D: (a boolean)\n",
      "\t\tuse 2D rigid body mode - ignores dof\n",
      "\t\tflag: -2D\n",
      "\tsave_log: (a boolean)\n",
      "\t\tsave to log file\n",
      "\tschedule: (an existing file name)\n",
      "\t\treplaces default schedule\n",
      "\t\tflag: -schedule %s\n",
      "\tsearchr_x: (a list of from 2 to 2 items which are an integer (int or\n",
      "\t\t long))\n",
      "\t\tsearch angles along x-axis, in degrees\n",
      "\t\tflag: -searchrx %s\n",
      "\tsearchr_y: (a list of from 2 to 2 items which are an integer (int or\n",
      "\t\t long))\n",
      "\t\tsearch angles along y-axis, in degrees\n",
      "\t\tflag: -searchry %s\n",
      "\tsearchr_z: (a list of from 2 to 2 items which are an integer (int or\n",
      "\t\t long))\n",
      "\t\tsearch angles along z-axis, in degrees\n",
      "\t\tflag: -searchrz %s\n",
      "\tsinc_width: (an integer (int or long))\n",
      "\t\tfull-width in voxels\n",
      "\t\tflag: -sincwidth %d\n",
      "\tsinc_window: ('rectangular' or 'hanning' or 'blackman')\n",
      "\t\tsinc window\n",
      "\t\tflag: -sincwindow %s\n",
      "\tterminal_output: ('stream' or 'allatonce' or 'file' or 'none')\n",
      "\t\tControl terminal output: `stream` - displays to terminal immediately\n",
      "\t\t(default), `allatonce` - waits till command is finished to display\n",
      "\t\toutput, `file` - writes output to file, `none` - output is ignored\n",
      "\tuses_qform: (a boolean)\n",
      "\t\tinitialize using sform or qform\n",
      "\t\tflag: -usesqform\n",
      "\tverbose: (an integer (int or long))\n",
      "\t\tverbose mode, 0 is least\n",
      "\t\tflag: -verbose %d\n",
      "\twm_seg: (a file name)\n",
      "\t\twhite matter segmentation volume needed by BBR cost function\n",
      "\t\tflag: -wmseg %s\n",
      "\twmcoords: (a file name)\n",
      "\t\twhite matter boundary coordinates for BBR cost function\n",
      "\t\tflag: -wmcoords %s\n",
      "\twmnorms: (a file name)\n",
      "\t\twhite matter boundary normals for BBR cost function\n",
      "\t\tflag: -wmnorms %s\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tout_file: (an existing file name)\n",
      "\t\tpath/name of registered file (if generated)\n",
      "\tout_log: (a file name)\n",
      "\t\tpath/name of output log (if generated)\n",
      "\tout_matrix_file: (an existing file name)\n",
      "\t\tpath/name of calculated affine transform (if generated)\n",
      "\n",
      "References::\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def reg_workflow(name = 'registration'):\n",
    "    \"\"\"Create a FEAT preprocessing workflow\n",
    "    Parameters\n",
    "    ----------\n",
    "    ::\n",
    "        name : name of workflow (default: 'registration')\n",
    "    Inputs::\n",
    "        inputspec.source_files : files (filename or list of filenames to register)\n",
    "        inputspec.mean_image : reference image to use\n",
    "        inputspec.anatomical_image : anatomical image to coregister to\n",
    "        inputspec.target_image : registration target\n",
    "    Outputs::\n",
    "        outputspec.func2anat_transform : FLIRT transform\n",
    "        outputspec.anat2target_transform : FLIRT+FNIRT transform\n",
    "        outputspec.transformed_files : transformed files in target space\n",
    "        outputspec.transformed_mean : mean image in target space\n",
    "    Example\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "    register = Workflow(name=name)\n",
    "\n",
    "    inputnode = Node(interface=util.IdentityInterface(fields=['source_files',\n",
    "                                                                 'anatomical_image',\n",
    "                                                                 'target_image']),\n",
    "                        name='inputspec')\n",
    "    outputnode = Node(interface=util.IdentityInterface(fields=['func2anat_transform',\n",
    "                                                                  'anat2target_transform',\n",
    "                                                                  'transformed_files',\n",
    "                                                                  'transformed_mean',\n",
    "                                                                  ]),\n",
    "                         name='outputspec')\n",
    "    meanfunc = MapNode(fsl.ImageMaths(op_string='-Tmean',suffix='_mean'), \n",
    "                       iterfield = ['in_file'], \n",
    "                       name = 'meanfunc')\n",
    "    register.connect(inputnode, 'source_files', meanfunc, 'in_file')\n",
    "    \"\"\"\n",
    "    Estimate the tissue classes from the anatomical image. But use spm's segment\n",
    "    as FSL appears to be breaking.\n",
    "    \"\"\"\n",
    "\n",
    "    stripper = MapNode(fsl.BET(), iterfield = ['in_file'],\n",
    "                       name='stripper')\n",
    "    register.connect(inputnode, 'anatomical_image', stripper, 'in_file')\n",
    "    fast = MapNode(fsl.FAST(), iterfield = ['in_files'], name='fast')\n",
    "    register.connect(stripper, 'out_file', fast, 'in_files')\n",
    "\n",
    "    \"\"\"\n",
    "    Binarize the segmentation\n",
    "    \"\"\"\n",
    "\n",
    "    binarize = MapNode(fsl.ImageMaths(op_string='-nan -thr 0.5 -bin'),\n",
    "                       iterfield = ['in_file'],\n",
    "                       name='binarize')\n",
    "    pickindex = lambda x, i: x[i]\n",
    "    register.connect(fast, ('partial_volume_files', pickindex, 2),\n",
    "                     binarize, 'in_file')\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate rigid transform from mean image to anatomical image\n",
    "    \"\"\"\n",
    "\n",
    "    mean2anat = MapNode(fsl.FLIRT(), \n",
    "                        iterfield = ['in_file','reference'],\n",
    "                        name='mean2anat')\n",
    "    mean2anat.inputs.dof = 6\n",
    "    register.connect(meanfunc,'out_file', mean2anat, 'in_file')\n",
    "    register.connect(stripper, 'out_file', mean2anat, 'reference')\n",
    "\n",
    "    \"\"\"\n",
    "    Now use bbr cost function to improve the transform\n",
    "    \"\"\"\n",
    "\n",
    "    mean2anatbbr = MapNode(fsl.FLIRT(), \n",
    "                        iterfield = ['in_file','wm_seg','reference','in_matrix_file'],\n",
    "                        name='mean2anatbbr')\n",
    "    mean2anatbbr.inputs.dof = 6\n",
    "    mean2anatbbr.inputs.cost = 'bbr'\n",
    "    mean2anatbbr.inputs.schedule = os.path.join(os.getenv('FSLDIR'),\n",
    "                                                'etc/flirtsch/bbr.sch')\n",
    "    register.connect(meanfunc,'out_file', mean2anatbbr, 'in_file')\n",
    "    register.connect(binarize, 'out_file', mean2anatbbr, 'wm_seg')\n",
    "    register.connect(inputnode, 'anatomical_image', mean2anatbbr, 'reference')\n",
    "    register.connect(mean2anat, 'out_matrix_file',\n",
    "                     mean2anatbbr, 'in_matrix_file')\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate affine transform from anatomical to target\n",
    "    \"\"\"\n",
    "\n",
    "    anat2target_affine = MapNode(fsl.FLIRT(), iterfield = ['in_file','reference'],\n",
    "                                 name='anat2target_linear')\n",
    "    anat2target_affine.inputs.searchr_x = [-180, 180]\n",
    "    anat2target_affine.inputs.searchr_y = [-180, 180]\n",
    "    anat2target_affine.inputs.searchr_z = [-180, 180]\n",
    "    register.connect(stripper, 'out_file', anat2target_affine, 'in_file')\n",
    "    register.connect(inputnode, 'target_image',\n",
    "                     anat2target_affine, 'reference')\n",
    "\n",
    "\n",
    "#     register.connect(anat2target_affine, 'out_matrix_file',\n",
    "#                      anat2target_nonlinear, 'affine_file')\n",
    "#     register.connect(inputnode, 'anatomical_image',\n",
    "#                      anat2target_nonlinear, 'in_file')\n",
    "#     register.connect(inputnode, 'config_file',\n",
    "#                      anat2target_nonlinear, 'config_file')\n",
    "#     register.connect(inputnode, 'target_image',\n",
    "#                      anat2target_nonlinear, 'ref_file')\n",
    "\n",
    "    \"\"\"\n",
    "    Transform the mean image. First to anatomical and then to target\n",
    "    \"\"\"\n",
    "\n",
    "    warpmean = MapNode(fsl.ApplyWarp(interp='spline'), \n",
    "                       iterfield = ['in_file','premat','ref_file','postmat'],\n",
    "                       name='warpmean')\n",
    "    register.connect(meanfunc,'out_file', warpmean, 'in_file')\n",
    "    register.connect(mean2anatbbr, 'out_matrix_file', warpmean, 'premat')\n",
    "    register.connect(inputnode, 'target_image', warpmean, 'ref_file')\n",
    "#     register.connect(anat2target_nonlinear, 'fieldcoeff_file',\n",
    "#                      warpmean, 'field_file')\n",
    "    register.connect(anat2target_affine, 'out_matrix_file',\n",
    "                     warpmean, 'postmat')\n",
    "    \n",
    "    \"\"\"\n",
    "    Transform the remaining images. First to anatomical and then to target\n",
    "    \"\"\"\n",
    "\n",
    "    warpall = MapNode(fsl.ApplyWarp(interp='spline'),\n",
    "                         iterfield=['in_file',],\n",
    "                         nested=True,\n",
    "                         name='warpall')\n",
    "    register.connect(inputnode, 'source_files', warpall, 'in_file')\n",
    "    register.connect(mean2anatbbr, 'out_matrix_file', warpall, 'premat')\n",
    "    register.connect(inputnode, 'target_image', warpall, 'ref_file')\n",
    "#     register.connect(anat2target_nonlinear, 'fieldcoeff_file',\n",
    "#                      warpall, 'field_file')\n",
    "    register.connect(anat2target_affine, 'out_matrix_file',\n",
    "                     warpall, 'postmat')\n",
    "\n",
    "    \"\"\"\n",
    "    Assign all the output files\n",
    "    \"\"\"\n",
    "\n",
    "    register.connect(warpmean, 'out_file', outputnode, 'transformed_mean')\n",
    "    register.connect(warpall, 'out_file', outputnode, 'transformed_files')\n",
    "    register.connect(mean2anatbbr, 'out_matrix_file',\n",
    "                     outputnode, 'func2anat_transform')\n",
    "#     register.connect(anat2target_nonlinear, 'fieldcoeff_file',\n",
    "#                      outputnode, 'anat2target_transform')\n",
    "    register.connect(anat2target_affine, 'out_matrix_file',\n",
    "                     outputnode, 'anat2target_transform')\n",
    "    \n",
    "\n",
    "    \n",
    "    return register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps command **fnirt**\n",
      "\n",
      "Use FSL FNIRT for non-linear registration.\n",
      "\n",
      "For complete details, see the `FNIRT Documentation.\n",
      "<https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FNIRT>`_\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from nipype.interfaces import fsl\n",
      ">>> from nipype.testing import example_data\n",
      ">>> fnt = fsl.FNIRT(affine_file=example_data('trans.mat'))\n",
      ">>> res = fnt.run(ref_file=example_data('mni.nii', in_file=example_data('structural.nii')) #doctest: +SKIP\n",
      "\n",
      "T1 -> Mni153\n",
      "\n",
      ">>> from nipype.interfaces import fsl\n",
      ">>> fnirt_mprage = fsl.FNIRT()\n",
      ">>> fnirt_mprage.inputs.in_fwhm = [8, 4, 2, 2]\n",
      ">>> fnirt_mprage.inputs.subsampling_scheme = [4, 2, 1, 1]\n",
      "\n",
      "Specify the resolution of the warps\n",
      "\n",
      ">>> fnirt_mprage.inputs.warp_resolution = (6, 6, 6)\n",
      ">>> res = fnirt_mprage.run(in_file='structural.nii', ref_file='mni.nii', warped_file='warped.nii', fieldcoeff_file='fieldcoeff.nii')#doctest: +SKIP\n",
      "\n",
      "We can check the command line and confirm that it's what we expect.\n",
      "\n",
      ">>> fnirt_mprage.cmdline  #doctest: +SKIP\n",
      "'fnirt --cout=fieldcoeff.nii --in=structural.nii --infwhm=8,4,2,2 --ref=mni.nii --subsamp=4,2,1,1 --warpres=6,6,6 --iout=warped.nii'\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tin_file: (an existing file name)\n",
      "\t\tname of input image\n",
      "\t\tflag: --in=%s\n",
      "\tref_file: (an existing file name)\n",
      "\t\tname of reference image\n",
      "\t\tflag: --ref=%s\n",
      "\n",
      "\t[Optional]\n",
      "\taffine_file: (an existing file name)\n",
      "\t\tname of file containing affine transform\n",
      "\t\tflag: --aff=%s\n",
      "\tapply_inmask: (a list of items which are 0 or 1)\n",
      "\t\tlist of iterations to use input mask on (1 to use, 0 to skip)\n",
      "\t\tflag: --applyinmask=%s\n",
      "\t\tmutually_exclusive: skip_inmask\n",
      "\tapply_intensity_mapping: (a list of items which are 0 or 1)\n",
      "\t\tList of subsampling levels to apply intensity mapping for (0 to\n",
      "\t\tskip, 1 to apply)\n",
      "\t\tflag: --estint=%s\n",
      "\t\tmutually_exclusive: skip_intensity_mapping\n",
      "\tapply_refmask: (a list of items which are 0 or 1)\n",
      "\t\tlist of iterations to use reference mask on (1 to use, 0 to skip)\n",
      "\t\tflag: --applyrefmask=%s\n",
      "\t\tmutually_exclusive: skip_refmask\n",
      "\targs: (a unicode string)\n",
      "\t\tAdditional parameters to the command\n",
      "\t\tflag: %s\n",
      "\tbias_regularization_lambda: (a float)\n",
      "\t\tWeight of regularisation for bias-field, default 10000\n",
      "\t\tflag: --biaslambda=%f\n",
      "\tbiasfield_resolution: (a tuple of the form: (an integer (int or\n",
      "\t\t long), an integer (int or long), an integer (int or long)))\n",
      "\t\tResolution (in mm) of bias-field modelling local intensities,\n",
      "\t\tdefault 50, 50, 50\n",
      "\t\tflag: --biasres=%d,%d,%d\n",
      "\tconfig_file: ('T1_2_MNI152_2mm' or 'FA_2_FMRIB58_1mm' or an existing\n",
      "\t\t file name)\n",
      "\t\tName of config file specifying command line arguments\n",
      "\t\tflag: --config=%s\n",
      "\tderive_from_ref: (a boolean)\n",
      "\t\tIf true, ref image is used to calculate derivatives. Default false\n",
      "\t\tflag: --refderiv\n",
      "\tenviron: (a dictionary with keys which are a bytes or None or a value\n",
      "\t\t of class 'str' and with values which are a bytes or None or a value\n",
      "\t\t of class 'str', nipype default value: {})\n",
      "\t\tEnvironment variables\n",
      "\tfield_file: (a boolean or a file name)\n",
      "\t\tname of output file with field or true\n",
      "\t\tflag: --fout=%s\n",
      "\tfieldcoeff_file: (a boolean or a file name)\n",
      "\t\tname of output file with field coefficients or true\n",
      "\t\tflag: --cout=%s\n",
      "\thessian_precision: ('double' or 'float')\n",
      "\t\tPrecision for representing Hessian, double or float. Default double\n",
      "\t\tflag: --numprec=%s\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tin_fwhm: (a list of items which are an integer (int or long))\n",
      "\t\tFWHM (in mm) of gaussian smoothing kernel for input volume, default\n",
      "\t\t[6, 4, 2, 2]\n",
      "\t\tflag: --infwhm=%s\n",
      "\tin_intensitymap_file: (a list of from 1 to 2 items which are an\n",
      "\t\t existing file name)\n",
      "\t\tname of file/files containing initial intensity mapping usually\n",
      "\t\tgenerated by previous fnirt run\n",
      "\t\tflag: --intin=%s\n",
      "\tinmask_file: (an existing file name)\n",
      "\t\tname of file with mask in input image space\n",
      "\t\tflag: --inmask=%s\n",
      "\tinmask_val: (a float)\n",
      "\t\tValue to mask out in --in image. Default =0.0\n",
      "\t\tflag: --impinval=%f\n",
      "\tintensity_mapping_model: ('none' or 'global_linear' or\n",
      "\t\t 'global_non_linearlocal_linear' or 'global_non_linear_with_bias' or\n",
      "\t\t 'local_non_linear')\n",
      "\t\tModel for intensity-mapping\n",
      "\t\tflag: --intmod=%s\n",
      "\tintensity_mapping_order: (an integer (int or long))\n",
      "\t\tOrder of poynomial for mapping intensities, default 5\n",
      "\t\tflag: --intorder=%d\n",
      "\tinwarp_file: (an existing file name)\n",
      "\t\tname of file containing initial non-linear warps\n",
      "\t\tflag: --inwarp=%s\n",
      "\tjacobian_file: (a boolean or a file name)\n",
      "\t\tname of file for writing out the Jacobian of the field (for\n",
      "\t\tdiagnostic or VBM purposes)\n",
      "\t\tflag: --jout=%s\n",
      "\tjacobian_range: (a tuple of the form: (a float, a float))\n",
      "\t\tAllowed range of Jacobian determinants, default 0.01, 100.0\n",
      "\t\tflag: --jacrange=%f,%f\n",
      "\tlog_file: (a file name)\n",
      "\t\tName of log-file\n",
      "\t\tflag: --logout=%s\n",
      "\tmax_nonlin_iter: (a list of items which are an integer (int or long))\n",
      "\t\tMax # of non-linear iterations list, default [5, 5, 5, 5]\n",
      "\t\tflag: --miter=%s\n",
      "\tmodulatedref_file: (a boolean or a file name)\n",
      "\t\tname of file for writing out intensity modulated --ref (for\n",
      "\t\tdiagnostic purposes)\n",
      "\t\tflag: --refout=%s\n",
      "\tout_intensitymap_file: (a boolean or a file name)\n",
      "\t\tname of files for writing information pertaining to intensity\n",
      "\t\tmapping\n",
      "\t\tflag: --intout=%s\n",
      "\toutput_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "\t\t 'NIFTI_PAIR_GZ')\n",
      "\t\tFSL output type\n",
      "\tref_fwhm: (a list of items which are an integer (int or long))\n",
      "\t\tFWHM (in mm) of gaussian smoothing kernel for ref volume, default\n",
      "\t\t[4, 2, 0, 0]\n",
      "\t\tflag: --reffwhm=%s\n",
      "\trefmask_file: (an existing file name)\n",
      "\t\tname of file with mask in reference space\n",
      "\t\tflag: --refmask=%s\n",
      "\trefmask_val: (a float)\n",
      "\t\tValue to mask out in --ref image. Default =0.0\n",
      "\t\tflag: --imprefval=%f\n",
      "\tregularization_lambda: (a list of items which are a float)\n",
      "\t\tWeight of regularisation, default depending on --ssqlambda and\n",
      "\t\t--regmod switches. See user documetation.\n",
      "\t\tflag: --lambda=%s\n",
      "\tregularization_model: ('membrane_energy' or 'bending_energy')\n",
      "\t\tModel for regularisation of warp-field [membrane_energy\n",
      "\t\tbending_energy], default bending_energy\n",
      "\t\tflag: --regmod=%s\n",
      "\tskip_implicit_in_masking: (a boolean)\n",
      "\t\tskip implicit masking based on value in --in image. Default = 0\n",
      "\t\tflag: --impinm=0\n",
      "\tskip_implicit_ref_masking: (a boolean)\n",
      "\t\tskip implicit masking based on value in --ref image. Default = 0\n",
      "\t\tflag: --imprefm=0\n",
      "\tskip_inmask: (a boolean)\n",
      "\t\tskip specified inmask if set, default false\n",
      "\t\tflag: --applyinmask=0\n",
      "\t\tmutually_exclusive: apply_inmask\n",
      "\tskip_intensity_mapping: (a boolean)\n",
      "\t\tSkip estimate intensity-mapping default false\n",
      "\t\tflag: --estint=0\n",
      "\t\tmutually_exclusive: apply_intensity_mapping\n",
      "\tskip_lambda_ssq: (a boolean)\n",
      "\t\tIf true, lambda is not weighted by current ssq, default false\n",
      "\t\tflag: --ssqlambda=0\n",
      "\tskip_refmask: (a boolean)\n",
      "\t\tSkip specified refmask if set, default false\n",
      "\t\tflag: --applyrefmask=0\n",
      "\t\tmutually_exclusive: apply_refmask\n",
      "\tspline_order: (an integer (int or long))\n",
      "\t\tOrder of spline, 2->Qadratic spline, 3->Cubic spline. Default=3\n",
      "\t\tflag: --splineorder=%d\n",
      "\tsubsampling_scheme: (a list of items which are an integer (int or\n",
      "\t\t long))\n",
      "\t\tsub-sampling scheme, list, default [4, 2, 1, 1]\n",
      "\t\tflag: --subsamp=%s\n",
      "\tterminal_output: ('stream' or 'allatonce' or 'file' or 'none')\n",
      "\t\tControl terminal output: `stream` - displays to terminal immediately\n",
      "\t\t(default), `allatonce` - waits till command is finished to display\n",
      "\t\toutput, `file` - writes output to file, `none` - output is ignored\n",
      "\twarp_resolution: (a tuple of the form: (an integer (int or long), an\n",
      "\t\t integer (int or long), an integer (int or long)))\n",
      "\t\t(approximate) resolution (in mm) of warp basis in x-, y- and\n",
      "\t\tz-direction, default 10, 10, 10\n",
      "\t\tflag: --warpres=%d,%d,%d\n",
      "\twarped_file: (a file name)\n",
      "\t\tname of output image\n",
      "\t\tflag: --iout=%s\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tfield_file: (a file name)\n",
      "\t\tfile with warp field\n",
      "\tfieldcoeff_file: (an existing file name)\n",
      "\t\tfile with field coefficients\n",
      "\tjacobian_file: (a file name)\n",
      "\t\tfile containing Jacobian of the field\n",
      "\tlog_file: (a file name)\n",
      "\t\tName of log-file\n",
      "\tmodulatedref_file: (a file name)\n",
      "\t\tfile containing intensity modulated --ref\n",
      "\tout_intensitymap_file: (a list of from 2 to 2 items which are a file\n",
      "\t\t name)\n",
      "\t\tfiles containing info pertaining to intensity mapping\n",
      "\twarped_file: (an existing file name)\n",
      "\t\twarped image\n",
      "\n",
      "References::\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fsl.FNIRT.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps command **applywarp**\n",
      "\n",
      "Use FSL's applywarp to apply the results of a FNIRT registration\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from nipype.interfaces import fsl\n",
      ">>> from nipype.testing import example_data\n",
      ">>> aw = fsl.ApplyWarp()\n",
      ">>> aw.inputs.in_file = example_data('structural.nii')\n",
      ">>> aw.inputs.ref_file = example_data('mni.nii')\n",
      ">>> aw.inputs.field_file = 'my_coefficients_filed.nii' #doctest: +SKIP\n",
      ">>> res = aw.run() #doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tin_file: (an existing file name)\n",
      "\t\timage to be warped\n",
      "\t\tflag: --in=%s, position: 0\n",
      "\tref_file: (an existing file name)\n",
      "\t\treference image\n",
      "\t\tflag: --ref=%s, position: 1\n",
      "\n",
      "\t[Optional]\n",
      "\tabswarp: (a boolean)\n",
      "\t\ttreat warp field as absolute: x' = w(x)\n",
      "\t\tflag: --abs\n",
      "\t\tmutually_exclusive: relwarp\n",
      "\targs: (a unicode string)\n",
      "\t\tAdditional parameters to the command\n",
      "\t\tflag: %s\n",
      "\tdatatype: ('char' or 'short' or 'int' or 'float' or 'double')\n",
      "\t\tForce output data type [char short int float double].\n",
      "\t\tflag: --datatype=%s\n",
      "\tenviron: (a dictionary with keys which are a bytes or None or a value\n",
      "\t\t of class 'str' and with values which are a bytes or None or a value\n",
      "\t\t of class 'str', nipype default value: {})\n",
      "\t\tEnvironment variables\n",
      "\tfield_file: (an existing file name)\n",
      "\t\tfile containing warp field\n",
      "\t\tflag: --warp=%s\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tinterp: ('nn' or 'trilinear' or 'sinc' or 'spline')\n",
      "\t\tinterpolation method\n",
      "\t\tflag: --interp=%s, position: -2\n",
      "\tmask_file: (an existing file name)\n",
      "\t\tfilename for mask image (in reference space)\n",
      "\t\tflag: --mask=%s\n",
      "\tout_file: (a file name)\n",
      "\t\toutput filename\n",
      "\t\tflag: --out=%s, position: 2\n",
      "\toutput_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "\t\t 'NIFTI_PAIR_GZ')\n",
      "\t\tFSL output type\n",
      "\tpostmat: (an existing file name)\n",
      "\t\tfilename for post-transform (affine matrix)\n",
      "\t\tflag: --postmat=%s\n",
      "\tpremat: (an existing file name)\n",
      "\t\tfilename for pre-transform (affine matrix)\n",
      "\t\tflag: --premat=%s\n",
      "\trelwarp: (a boolean)\n",
      "\t\ttreat warp field as relative: x' = x + w(x)\n",
      "\t\tflag: --rel, position: -1\n",
      "\t\tmutually_exclusive: abswarp\n",
      "\tsuperlevel: ('a' or an integer (int or long))\n",
      "\t\tlevel of intermediary supersampling, a for 'automatic' or integer\n",
      "\t\tlevel. Default = 2\n",
      "\t\tflag: --superlevel=%s\n",
      "\tsupersample: (a boolean)\n",
      "\t\tintermediary supersampling of output, default is off\n",
      "\t\tflag: --super\n",
      "\tterminal_output: ('stream' or 'allatonce' or 'file' or 'none')\n",
      "\t\tControl terminal output: `stream` - displays to terminal immediately\n",
      "\t\t(default), `allatonce` - waits till command is finished to display\n",
      "\t\toutput, `file` - writes output to file, `none` - output is ignored\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tout_file: (an existing file name)\n",
      "\t\tWarped output file\n",
      "\n",
      "References::\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fsl.ApplyWarp.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3999447/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3283638/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/2154093/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/1065809/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/4222184/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3334426/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/4098356/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/3003775/session_1/rest_1/rest_linearMNI3mm.nii.gz\n",
    "/home/deepak/Desktop/funcConn/funcConnGUI/data/NYU_Cocaine/cocaine/1915879/session_1/rest_1/rest_linearMNI3mm.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
